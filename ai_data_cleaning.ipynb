{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMIiQqPdyRaEhZObJX37/Fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdomingo2029/aai_530_final_project_group_4/blob/master/ai_data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtEx43QTbEJ2"
      },
      "outputs": [],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H80cVKV3bvUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3bbf01-ca31-42d5-af13-2603eb1d6f0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/WESAD.zip\""
      ],
      "metadata": {
        "id": "ni1oarDfbvL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66158b95"
      },
      "source": [
        "print('Listing contents of MyDrive:')\n",
        "!ls \"/content/drive/MyDrive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the exact path (Google Drive root is 'MyDrive')\n",
        "zip_path = '/content/drive/MyDrive/WESAD.zip'\n",
        "\n",
        "# 3. Check if the file exists before unzipping\n",
        "if os.path.exists(zip_path):\n",
        "    print(\"Found it! Unzipping now...\")\n",
        "    !unzip -q \"{zip_path}\" -d \"/content/WESAD_data\"\n",
        "    print(\"Done! Files are now in the 'WESAD_data' folder on the left sidebar.\")\n",
        "else:\n",
        "    print(\"Still can't see it. Make sure the file is in the main 'My Drive' folder, not a subfolder.\")"
      ],
      "metadata": {
        "id": "yH0pkVivmCPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92c129c-fcc7-4b44-96a1-550508b88c12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found it! Unzipping now...\n",
            "error:  zipfile read error\n",
            "Done! Files are now in the 'WESAD_data' folder on the left sidebar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebd61aa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379e65e1-bc33-437c-8a91-eb03ae5b0820"
      },
      "source": [
        "print('Listing contents of the unzipped WESAD data directory:')\n",
        "!ls -F /content/WESAD_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of the unzipped WESAD data directory:\n",
            "WESAD/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbb4aa9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3faa5f-a188-447a-ef95-72dd4d942e08"
      },
      "source": [
        "print('Listing contents of the WESAD subdirectory:')\n",
        "!ls -F /content/WESAD_data/WESAD"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of the WESAD subdirectory:\n",
            "S10/  S11/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "635b6015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86728f9-fb08-436d-e020-bd6de05b4eca"
      },
      "source": [
        "print('Listing contents of the S2 subdirectory:')\n",
        "!ls -F /content/WESAD_data/WESAD/S2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of the S2 subdirectory:\n",
            "ls: cannot access '/content/WESAD_data/WESAD/S2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b274afb1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the base path to the S2 subject data directory\n",
        "s2_data_path = '/content/WESAD_data/WESAD/S2'\n",
        "\n",
        "# Load the S2.pkl file into a pandas DataFrame\n",
        "df_s2_data = pd.read_pickle(f'{s2_data_path}/S2.pkl')\n",
        "\n",
        "# Load the S2_quest.csv file into a pandas DataFrame\n",
        "df_s2_quest = pd.read_csv(f'{s2_data_path}/S2_quest.csv')\n",
        "\n",
        "print(\"df_s2_data head:\")\n",
        "print(df_s2_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_quest head:\")\n",
        "print(df_s2_quest.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d85dabe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the base path to the S2 subject data directory\n",
        "s2_data_path = '/content/WESAD_data/WESAD/S2'\n",
        "\n",
        "# Load the S2.pkl file into a dictionary first\n",
        "s2_raw_data_dict = pd.read_pickle(f'{s2_data_path}/S2.pkl')\n",
        "\n",
        "# Extract 'chest' and 'wrist' signals and convert them to DataFrames\n",
        "df_s2_chest_data = pd.DataFrame(s2_raw_data_dict['signal']['chest'])\n",
        "df_s2_wrist_data = pd.DataFrame(s2_raw_data_dict['signal']['wrist'])\n",
        "\n",
        "# Load the S2_quest.csv file into a pandas DataFrame\n",
        "df_s2_quest = pd.read_csv(f'{s2_data_path}/S2_quest.csv')\n",
        "\n",
        "print(\"df_s2_chest_data head:\")\n",
        "print(df_s2_chest_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_wrist_data head:\")\n",
        "print(df_s2_wrist_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_quest head:\")\n",
        "print(df_s2_quest.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8035ff91"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the base path to the S2 subject data directory\n",
        "s2_data_path = '/content/WESAD_data/WESAD/S2'\n",
        "\n",
        "# Load the S2.pkl file into a dictionary first\n",
        "s2_raw_data_dict = pd.read_pickle(f'{s2_data_path}/S2.pkl')\n",
        "\n",
        "# Process 'chest' signals\n",
        "chest_signals = s2_raw_data_dict['signal']['chest']\n",
        "chest_data = {}\n",
        "for sensor_name, data_array in chest_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is typically 3-axis, so create three columns\n",
        "        chest_data['ACC_x'] = data_array[:, 0]\n",
        "        chest_data['ACC_y'] = data_array[:, 1]\n",
        "        chest_data['ACC_z'] = data_array[:, 2]\n",
        "    else:\n",
        "        # Other sensors are typically 1D\n",
        "        chest_data[sensor_name] = data_array\n",
        "\n",
        "df_s2_chest_data = pd.DataFrame(chest_data)\n",
        "\n",
        "# Process 'wrist' signals\n",
        "wrist_signals = s2_raw_data_dict['signal']['wrist']\n",
        "wrist_data = {}\n",
        "for sensor_name, data_array in wrist_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is typically 3-axis, so create three columns\n",
        "        wrist_data['ACC_x'] = data_array[:, 0]\n",
        "        wrist_data['ACC_y'] = data_array[:, 1]\n",
        "        wrist_data['ACC_z'] = data_array[:, 2]\n",
        "    else:\n",
        "        # Other sensors are typically 1D\n",
        "        wrist_data[sensor_name] = data_array\n",
        "\n",
        "df_s2_wrist_data = pd.DataFrame(wrist_data)\n",
        "\n",
        "# Load the S2_quest.csv file into a pandas DataFrame\n",
        "df_s2_quest = pd.read_csv(f'{s2_data_path}/S2_quest.csv')\n",
        "\n",
        "print(\"df_s2_chest_data head:\")\n",
        "print(df_s2_chest_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_wrist_data head:\")\n",
        "print(df_s2_wrist_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_quest head:\")\n",
        "print(df_s2_quest.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2b017ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the base path to the S2 subject data directory\n",
        "s2_data_path = '/content/WESAD_data/WESAD/S2'\n",
        "\n",
        "# Load the S2.pkl file into a dictionary first\n",
        "s2_raw_data_dict = pd.read_pickle(f'{s2_data_path}/S2.pkl')\n",
        "\n",
        "# Process 'chest' signals\n",
        "chest_signals = s2_raw_data_dict['signal']['chest']\n",
        "chest_data = {}\n",
        "for sensor_name, data_array in chest_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is typically 3-axis, so create three columns\n",
        "        chest_data['ACC_x'] = data_array[:, 0]\n",
        "        chest_data['ACC_y'] = data_array[:, 1]\n",
        "        chest_data['ACC_z'] = data_array[:, 2]\n",
        "    else:\n",
        "        # Other sensors might be 2D arrays with a single column, flatten them\n",
        "        chest_data[sensor_name] = data_array.flatten()\n",
        "\n",
        "df_s2_chest_data = pd.DataFrame(chest_data)\n",
        "\n",
        "# Process 'wrist' signals\n",
        "wrist_signals = s2_raw_data_dict['signal']['wrist']\n",
        "wrist_data = {}\n",
        "for sensor_name, data_array in wrist_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is typically 3-axis, so create three columns\n",
        "        wrist_data['ACC_x'] = data_array[:, 0]\n",
        "        wrist_data['ACC_y'] = data_array[:, 1]\n",
        "        wrist_data['ACC_z'] = data_array[:, 2]\n",
        "    else:\n",
        "        # Other sensors might be 2D arrays with a single column, flatten them\n",
        "        wrist_data[sensor_name] = data_array.flatten()\n",
        "\n",
        "df_s2_wrist_data = pd.DataFrame(wrist_data)\n",
        "\n",
        "# Load the S2_quest.csv file into a pandas DataFrame\n",
        "df_s2_quest = pd.read_csv(f'{s2_data_path}/S2_quest.csv')\n",
        "\n",
        "print(\"df_s2_chest_data head:\")\n",
        "print(df_s2_chest_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_wrist_data head:\")\n",
        "print(df_s2_wrist_data.head())\n",
        "\n",
        "print(\"\\ndf_s2_quest head:\")\n",
        "print(df_s2_quest.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c05627fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "5f1ecc07-71f0-4be8-a146-1e1f53d25212"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the base path to the S2 subject data directory\n",
        "s2_data_path = '/content/WESAD_data/WESAD/S2'\n",
        "\n",
        "# Load the S2.pkl file into a dictionary first\n",
        "s2_raw_data_dict = pd.read_pickle(f'{s2_data_path}/S2.pkl')\n",
        "\n",
        "# Initialize dictionaries to hold individual sensor DataFrames\n",
        "chest_dataframes = {}\n",
        "wrist_dataframes = {}\n",
        "\n",
        "# Process 'chest' signals\n",
        "chest_signals = s2_raw_data_dict['signal']['chest']\n",
        "for sensor_name, data_array in chest_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is 3-axis, create three columns\n",
        "        chest_dataframes[sensor_name] = pd.DataFrame(data_array, columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
        "    else:\n",
        "        # Other sensors are typically 1D or 2D with one column, flatten and create a DataFrame\n",
        "        chest_dataframes[sensor_name] = pd.DataFrame(data_array.flattenbase_data_path = '/content/WESAD_data/' # Corrected path\n",
        "         (), columns=[sensor_name])\n",
        "\n",
        "# Process 'wrist' signals\n",
        "wrist_signals = s2_raw_data_dict['signal']['wrist']\n",
        "for sensor_name, data_array in wrist_signals.items():\n",
        "    if sensor_name == 'ACC':\n",
        "        # Accelerometer data is 3-axis, create three columns\n",
        "        wrist_dataframes[sensor_name] = pd.DataFrame(data_array, columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
        "    else:\n",
        "        # Other sensors are typically 1D or 2D with one column, flatten and create a DataFrame\n",
        "        wrist_dataframes[sensor_name] = pd.DataFrame(data_array.flatten(), columns=[sensor_name])\n",
        "\n",
        "# Load the S2_quest.csv file into a pandas DataFrame\n",
        "df_s2_quest = pd.read_csv(f'{s2_data_path}/S2_quest.csv')\n",
        "\n",
        "print(\"Chest DataFrames (first 5 rows of each):\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    print(f\"\\n{sensor_name}:\")\n",
        "    print(df.head())\n",
        "\n",
        "print(\"\\nWrist DataFrames (first 5 rows of each):\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    print(f\"\\n{sensor_name}:\")\n",
        "    print(df.head())\n",
        "\n",
        "print(\"\\ndf_s2_quest head:\")\n",
        "print(df_s2_quest.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/WESAD_data/WESAD/S2/S2.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-873747498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the S2.pkl file into a dictionary first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ms2_raw_data_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{s2_data_path}/S2.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize dictionaries to hold individual sensor DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/WESAD_data/WESAD/S2/S2.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Initialize dictionaries to hold individual sensor DataFrames from ALL subjects\n",
        "all_chest_dataframes = {}\n",
        "all_wrist_dataframes = {}\n",
        "all_quest_dataframes = {}\n",
        "\n",
        "# Base path to the WESAD data directory\n",
        "base_data_path = '/content/WESAD_data/WESAD'\n",
        "print(f\"Base data path: {base_data_path}\")\n",
        "print(f\"Does base path exist? {os.path.exists(base_data_path)}\")\n",
        "\n",
        "# Loop through subjects S2 to S17\n",
        "print(\"Starting loop through subjects S2-S17...\")\n",
        "for subject_id in range(2, 18):\n",
        "    subject_name = f'S{subject_id}'\n",
        "    print(f\"Looking for subject: {subject_name}\")\n",
        "    subject_data_path = os.path.join(base_data_path, subject_name)\n",
        "    pkl_file_path = os.path.join(subject_data_path, f'{subject_name}.pkl')\n",
        "    quest_file_path = os.path.join(subject_data_path, f'{subject_name}_quest.csv')\n",
        "\n",
        "    print(f\"Checking for pkl file: {pkl_file_path}\")\n",
        "    if os.path.exists(pkl_file_path):\n",
        "        print(f\"Processing {subject_name} data...\")\n",
        "        # Load the .pkl file\n",
        "        raw_data_dict = pd.read_pickle(pkl_file_path)\n",
        "\n",
        "        # Process 'chest' signals\n",
        "        if 'chest' in raw_data_dict['signal']:\n",
        "            chest_signals = raw_data_dict['signal']['chest']\n",
        "            for sensor_name, data_array in chest_signals.items():\n",
        "                key = f'{subject_name}_{sensor_name}'\n",
        "                if sensor_name == 'ACC':\n",
        "                    all_chest_dataframes[key] = pd.DataFrame(data_array, columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
        "                else:\n",
        "                    all_chest_dataframes[key] = pd.DataFrame(data_array.flatten(), columns=[sensor_name])\n",
        "\n",
        "        # Process 'wrist' signals\n",
        "        if 'wrist' in raw_data_dict['signal']:\n",
        "            wrist_signals = raw_data_dict['signal']['wrist']\n",
        "            for sensor_name, data_array in wrist_signals.items():\n",
        "                key = f'{subject_name}_{sensor_name}'\n",
        "                if sensor_name == 'ACC':\n",
        "                    all_wrist_dataframes[key] = pd.DataFrame(data_array, columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
        "                else:\n",
        "                    all_wrist_dataframes[key] = pd.DataFrame(data_array.flatten(), columns=[sensor_name])\n",
        "\n",
        "        # Load the _quest.csv file\n",
        "        if os.path.exists(quest_file_path):\n",
        "            all_quest_dataframes[subject_name] = pd.read_csv(quest_file_path)\n",
        "            print(f\"Loaded {subject_name}_quest.csv\")\n",
        "        else:\n",
        "            print(f\"Warning: {subject_name}_quest.csv not found.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Warning: {subject_name}.pkl not found at {pkl_file_path}\")\n",
        "\n",
        "print(\"\\nFinished loading data for all subjects.\")\n",
        "print(\"Total chest dataframes loaded:\", len(all_chest_dataframes))\n",
        "print(\"Total wrist dataframes loaded:\", len(all_wrist_dataframes))\n",
        "print(\"Total quest dataframes loaded:\", len(all_quest_dataframes))\n",
        "\n",
        "# For compatibility with the next cell, we'll make chest_dataframes and wrist_dataframes\n",
        "# point to the new dictionaries. And df_s2_quest will be S2's quest df.\n",
        "chest_dataframes = all_chest_dataframes\n",
        "wrist_dataframes = all_wrist_dataframes\n",
        "\n",
        "# Set df_s2_quest to S10's quest data if S2 is not available\n",
        "# This is a temporary fix due to missing S2 data\n",
        "if 'S2' in all_quest_dataframes:\n",
        "    df_s2_quest = all_quest_dataframes['S2']\n",
        "elif 'S10' in all_quest_dataframes:\n",
        "    df_s2_quest = all_quest_dataframes['S10']\n",
        "    print(\"Using S10 quest data as a fallback for df_s2_quest due to missing S2 data.\")\n",
        "else:\n",
        "    df_s2_quest = None # Or handle error if S2 quest is essential\n",
        "\n",
        "# Define s2_data_path for compatibility, defaulting to S10 if S2 is missing\n",
        "if os.path.exists(os.path.join(base_data_path, 'S2')):\n",
        "    s2_data_path = os.path.join(base_data_path, 'S2')\n",
        "elif os.path.exists(os.path.join(base_data_path, 'S10')):\n",
        "    s2_data_path = os.path.join(base_data_path, 'S10')\n",
        "    print(\"Using S10 data path as a fallback for s2_data_path due to missing S2 data.\")\n",
        "else:\n",
        "    s2_data_path = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0DMTPNUCqW-",
        "outputId": "fece7260-ac51-43bb-ffab-7010666cd757"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base data path: /content/WESAD_data/WESAD\n",
            "Does base path exist? True\n",
            "Starting loop through subjects S2-S17...\n",
            "Looking for subject: S2\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S2/S2.pkl\n",
            "Warning: S2.pkl not found at /content/WESAD_data/WESAD/S2/S2.pkl\n",
            "Looking for subject: S3\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S3/S3.pkl\n",
            "Warning: S3.pkl not found at /content/WESAD_data/WESAD/S3/S3.pkl\n",
            "Looking for subject: S4\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S4/S4.pkl\n",
            "Warning: S4.pkl not found at /content/WESAD_data/WESAD/S4/S4.pkl\n",
            "Looking for subject: S5\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S5/S5.pkl\n",
            "Warning: S5.pkl not found at /content/WESAD_data/WESAD/S5/S5.pkl\n",
            "Looking for subject: S6\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S6/S6.pkl\n",
            "Warning: S6.pkl not found at /content/WESAD_data/WESAD/S6/S6.pkl\n",
            "Looking for subject: S7\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S7/S7.pkl\n",
            "Warning: S7.pkl not found at /content/WESAD_data/WESAD/S7/S7.pkl\n",
            "Looking for subject: S8\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S8/S8.pkl\n",
            "Warning: S8.pkl not found at /content/WESAD_data/WESAD/S8/S8.pkl\n",
            "Looking for subject: S9\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S9/S9.pkl\n",
            "Warning: S9.pkl not found at /content/WESAD_data/WESAD/S9/S9.pkl\n",
            "Looking for subject: S10\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S10/S10.pkl\n",
            "Processing S10 data...\n",
            "Loaded S10_quest.csv\n",
            "Looking for subject: S11\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S11/S11.pkl\n",
            "Processing S11 data...\n",
            "Loaded S11_quest.csv\n",
            "Looking for subject: S12\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S12/S12.pkl\n",
            "Warning: S12.pkl not found at /content/WESAD_data/WESAD/S12/S12.pkl\n",
            "Looking for subject: S13\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S13/S13.pkl\n",
            "Warning: S13.pkl not found at /content/WESAD_data/WESAD/S13/S13.pkl\n",
            "Looking for subject: S14\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S14/S14.pkl\n",
            "Warning: S14.pkl not found at /content/WESAD_data/WESAD/S14/S14.pkl\n",
            "Looking for subject: S15\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S15/S15.pkl\n",
            "Warning: S15.pkl not found at /content/WESAD_data/WESAD/S15/S15.pkl\n",
            "Looking for subject: S16\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S16/S16.pkl\n",
            "Warning: S16.pkl not found at /content/WESAD_data/WESAD/S16/S16.pkl\n",
            "Looking for subject: S17\n",
            "Checking for pkl file: /content/WESAD_data/WESAD/S17/S17.pkl\n",
            "Warning: S17.pkl not found at /content/WESAD_data/WESAD/S17/S17.pkl\n",
            "\n",
            "Finished loading data for all subjects.\n",
            "Total chest dataframes loaded: 12\n",
            "Total wrist dataframes loaded: 8\n",
            "Total quest dataframes loaded: 2\n",
            "Using S10 quest data as a fallback for df_s2_quest due to missing S2 data.\n",
            "Using S10 data path as a fallback for s2_data_path due to missing S2 data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import resample\n",
        "\n",
        "# Target frequency for resampling\n",
        "TARGET_FREQ = 32  # Hz\n",
        "TOLERANCE = '10ms' # Tolerance for nearest matching\n",
        "\n",
        "# --- Resample Chest Data (Downsampling) ---\n",
        "resampled_chest_dataframes = {}\n",
        "# Iterate through the globally available chest_dataframes (which now contain S10/S11 data)\n",
        "for sensor_name_key, df in chest_dataframes.items():\n",
        "    # Only process S10 data if S2 is not available\n",
        "    if 'S2' in sensor_name_key and not os.path.exists(os.path.join(base_data_path, 'S2')):\n",
        "        continue # Skip S2 if it's not present\n",
        "\n",
        "    # Adapt sensor_name to be just the sensor type (e.g., 'ACC' from 'S10_ACC')\n",
        "    actual_sensor_name = sensor_name_key.split('_')[1] if '_' in sensor_name_key else sensor_name_key\n",
        "\n",
        "    if not df.empty and actual_sensor_name == 'ACC': # ACC is 700Hz\n",
        "        original_len = len(df)\n",
        "        if original_len > 1:\n",
        "            time_index = pd.to_timedelta(np.arange(original_len) / 700.0, unit='s')\n",
        "            df.index = time_index\n",
        "            resample_len = int(original_len * TARGET_FREQ / 700.0)\n",
        "            resampled_data = {}\n",
        "            for col in df.columns:\n",
        "                resampled_data[col] = resample(df[col], resample_len)\n",
        "            resampled_df = pd.DataFrame(resampled_data)\n",
        "            resampled_time_index = pd.to_timedelta(np.arange(resample_len) / float(TARGET_FREQ), unit='s')\n",
        "            resampled_df.index = resampled_time_index\n",
        "            resampled_chest_dataframes[sensor_name_key] = resampled_df\n",
        "            print(f\"Resampled {sensor_name_key} from {original_len} to {resample_len} points (700Hz to {TARGET_FREQ}Hz)\")\n",
        "        else:\n",
        "            resampled_chest_dataframes[sensor_name_key] = df.copy()\n",
        "            print(f\"Kept {sensor_name_key} as is (empty or single row)\")\n",
        "    else:\n",
        "        resampled_chest_dataframes[sensor_name_key] = df.copy()\n",
        "        if not df.empty:\n",
        "             original_len = len(df)\n",
        "             time_index = pd.to_timedelta(np.arange(original_len) / float(TARGET_FREQ), unit='s')\n",
        "             df.index = time_index\n",
        "             resampled_chest_dataframes[sensor_name_key].index = time_index\n",
        "             print(f\"Kept non-ACC {sensor_name_key} with {original_len} points, assumed {TARGET_FREQ}Hz\")\n",
        "        else:\n",
        "            print(f\"Kept non-ACC {sensor_name_key} as is (empty)\")\n",
        "\n",
        "# --- Resample Wrist Data (Upsampling/Downsampling) ---\n",
        "resampled_wrist_dataframes = {}\n",
        "wrist_original_freqs = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4}\n",
        "\n",
        "# Iterate through the globally available wrist_dataframes (which now contain S10/S11 data)\n",
        "for sensor_name_key, df in wrist_dataframes.items():\n",
        "    # Only process S10 data if S2 is not available\n",
        "    if 'S2' in sensor_name_key and not os.path.exists(os.path.join(base_data_path, 'S2')):\n",
        "        continue # Skip S2 if it's not present\n",
        "\n",
        "    actual_sensor_name = sensor_name_key.split('_')[1] if '_' in sensor_name_key else sensor_name_key\n",
        "\n",
        "    if not df.empty and actual_sensor_name in wrist_original_freqs:\n",
        "        original_freq = wrist_original_freqs[actual_sensor_name]\n",
        "        original_len = len(df)\n",
        "        if original_len > 1 and original_freq != TARGET_FREQ:\n",
        "            time_index = pd.to_timedelta(np.arange(original_len) / float(original_freq), unit='s')\n",
        "            df.index = time_index\n",
        "            resample_len = int(original_len * TARGET_FREQ / float(original_freq))\n",
        "            resampled_data = {}\n",
        "            for col in df.columns:\n",
        "                resampled_data[col] = resample(df[col], resample_len)\n",
        "            resampled_df = pd.DataFrame(resampled_data)\n",
        "            resampled_time_index = pd.to_timedelta(np.arange(resample_len) / float(TARGET_FREQ), unit='s')\n",
        "            resampled_df.index = resampled_time_index\n",
        "            resampled_wrist_dataframes[sensor_name_key] = resampled_df\n",
        "            print(f\"Resampled {sensor_name_key} from {original_len} to {resample_len} points ({original_freq}Hz to {TARGET_FREQ}Hz)\")\n",
        "        else:\n",
        "            if original_len > 0:\n",
        "                time_index = pd.to_timedelta(np.arange(original_len) / float(original_freq), unit='s')\n",
        "                df.index = time_index\n",
        "                resampled_wrist_dataframes[sensor_name_key] = df.copy()\n",
        "                print(f\"Kept {sensor_name_key} as is with {original_len} points (at/near {TARGET_FREQ}Hz or single row)\")\n",
        "            else:\n",
        "                resampled_wrist_dataframes[sensor_name_key] = df.copy()\n",
        "                print(f\"Kept {sensor_name_key} as is (empty)\")\n",
        "    else:\n",
        "        resampled_wrist_dataframes[sensor_name_key] = df.copy()\n",
        "        print(f\"Kept {sensor_name_key} as is (empty or not in freq map)\")\n",
        "\n",
        "print(\"\\nResampling complete.\")\n",
        "\n",
        "# --- Alignment ---\n",
        "# The following section expects df_event_timings which is created from df_s2_quest\n",
        "# We will use df_s2_quest (which might be S10's quest data as a fallback) to create df_event_timings\n",
        "if 'df_event_timings' not in locals() and 'df_event_timings' not in globals() and df_s2_quest is not None:\n",
        "    print(\"Creating df_event_timings from available df_s2_quest...\")\n",
        "    # 1. Locate and extract the string content from the relevant rows\n",
        "    order_str = df_s2_quest.iloc[0, 0]\n",
        "    start_str = df_s2_quest.iloc[1, 0]\n",
        "    end_str = df_s2_quest.iloc[2, 0]\n",
        "\n",
        "    # 2. Split by semicolon and clean the lists\n",
        "    def clean_split_list(s):\n",
        "        parts = s.replace('#', '').split(';')\n",
        "        return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "    cleaned_order = clean_split_list(order_str)\n",
        "    cleaned_start = clean_split_list(start_str)\n",
        "    cleaned_end = clean_split_list(end_str)\n",
        "\n",
        "    # 3. Create a list of event names (skipping the 'ORDER' label)\n",
        "    event_names = cleaned_order[1:]\n",
        "\n",
        "    # 4. Create dictionaries for START and END times, converting to float\n",
        "    start_times = {}\n",
        "    for i, event in enumerate(event_names):\n",
        "        if (i + 1) < len(cleaned_start):\n",
        "            try:\n",
        "                start_times[event] = float(cleaned_start[i + 1])\n",
        "            except ValueError:\n",
        "                start_times[event] = None\n",
        "\n",
        "    end_times = {}\n",
        "    for i, event in enumerate(event_names):\n",
        "        if (i + 1) < len(cleaned_end):\n",
        "            try:\n",
        "                end_times[event] = float(cleaned_end[i + 1])\n",
        "            except ValueError:\n",
        "                end_times[event] = None\n",
        "\n",
        "    # 5. Combine into a new pandas DataFrame\n",
        "    events_list = []\n",
        "    start_time_list = []\n",
        "    end_time_list = []\n",
        "\n",
        "    for event in event_names:\n",
        "        events_list.append(event)\n",
        "        start_time_list.append(start_times.get(event))\n",
        "        end_time_list.append(end_times.get(event))\n",
        "\n",
        "    df_event_timings = pd.DataFrame({\n",
        "        'Event': events_list,\n",
        "        'Start_Time': start_time_list,\n",
        "        'End_Time': end_time_list\n",
        "    })\n",
        "    print(\"df_event_timings created successfully.\")\n",
        "elif df_s2_quest is None:\n",
        "    print(\"Warning: df_s2_quest is None, cannot create df_event_timings. Using dummy values for alignment.\")\n",
        "    start_time = pd.to_datetime('1970-01-01 00:00:00') # Dummy start\n",
        "    end_time = pd.to_datetime('1970-01-01 00:05:00')   # Dummy end (5 mins later)\n",
        "    df_event_timings = pd.DataFrame({'Start_Time': [start_time], 'End_Time': [end_time]})\n",
        "else:\n",
        "    print(\"df_event_timings already exists.\")\n",
        "\n",
        "# Ensure Start_Time and End_Time are datetime objects for alignment\n",
        "df_event_timings['Start_Time'] = pd.to_datetime(df_event_timings['Start_Time'], unit='s', origin='unix')\n",
        "df_event_timings['End_Time'] = pd.to_datetime(df_event_timings['End_Time'], unit='s', origin='unix')\n",
        "\n",
        "start_time = df_event_timings['Start_Time'].iloc[0]\n",
        "end_time = df_event_timings['End_Time'].iloc[0]\n",
        "\n",
        "aligned_data = {}\n",
        "\n",
        "# Align resampled chest data\n",
        "for sensor_name_key, df in resampled_chest_dataframes.items():\n",
        "    if not df.empty and isinstance(df.index, pd.TimedeltaIndex):\n",
        "        df_abs_time = df.copy()\n",
        "        df_abs_time.index = start_time + df_abs_time.index\n",
        "        aligned_df = df_abs_time[(df_abs_time.index >= start_time) & (df_abs_time.index <= end_time)]\n",
        "        # Make index relative to start_time again for merging\n",
        "        aligned_df.index = aligned_df.index - start_time\n",
        "        aligned_data[f'chest_{sensor_name_key}'] = aligned_df\n",
        "        print(f\"Aligned chest_{sensor_name_key}\")\n",
        "\n",
        "# Align resampled wrist data\n",
        "for sensor_name_key, df in resampled_wrist_dataframes.items():\n",
        "    if not df.empty and isinstance(df.index, pd.TimedeltaIndex):\n",
        "        df_abs_time = df.copy()\n",
        "        df_abs_time.index = start_time + df_abs_time.index\n",
        "        aligned_df = df_abs_time[(df_abs_time.index >= start_time) & (df_abs_time.index <= end_time)]\n",
        "        aligned_df.index = aligned_df.index - start_time\n",
        "        aligned_data[f'wrist_{sensor_name_key}'] = aligned_df\n",
        "        print(f\"Aligned wrist_{sensor_name_key}\")\n",
        "\n",
        "# --- Consolidation ---\n",
        "df_final = pd.DataFrame()\n",
        "for sensor_key, df in aligned_data.items():\n",
        "    if not df.empty:\n",
        "        # Ensure unique column names by prepending sensor_key to original column names\n",
        "        df_renamed = df.rename(columns={col: f'{sensor_key}_{col}' for col in df.columns})\n",
        "        if df_final.empty:\n",
        "            df_final = df_renamed\n",
        "        else:\n",
        "            # Before merging, ensure indexes are unique or handle potential duplicates if they arise\n",
        "            # For now, relying on merge_asof handling potential non-exact index matches\n",
        "            df_final = pd.merge_asof(df_final.sort_index(), df_renamed.sort_index(), left_index=True, right_index=True, direction='nearest', tolerance=pd.Timedelta(TOLERANCE))\n",
        "\n",
        "print(\"\\nAlignment and Consolidation complete.\")\n",
        "print(\"Final DataFrame head:\")\n",
        "print(df_final.head())\n",
        "print(\"Final DataFrame info:\")\n",
        "df_final.info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDmEu1G6BKNg",
        "outputId": "495fe65d-99fa-43b9-b362-fe57d3cc02b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled S10_ACC from 3847200 to 175872 points (700Hz to 32Hz)\n",
            "Kept non-ACC S10_ECG with 3847200 points, assumed 32Hz\n",
            "Kept non-ACC S10_EMG with 3847200 points, assumed 32Hz\n",
            "Kept non-ACC S10_EDA with 3847200 points, assumed 32Hz\n",
            "Kept non-ACC S10_Temp with 3847200 points, assumed 32Hz\n",
            "Kept non-ACC S10_Resp with 3847200 points, assumed 32Hz\n",
            "Resampled S11_ACC from 3663100 to 167456 points (700Hz to 32Hz)\n",
            "Kept non-ACC S11_ECG with 3663100 points, assumed 32Hz\n",
            "Kept non-ACC S11_EMG with 3663100 points, assumed 32Hz\n",
            "Kept non-ACC S11_EDA with 3663100 points, assumed 32Hz\n",
            "Kept non-ACC S11_Temp with 3663100 points, assumed 32Hz\n",
            "Kept non-ACC S11_Resp with 3663100 points, assumed 32Hz\n",
            "Kept S10_ACC as is with 175872 points (at/near 32Hz or single row)\n",
            "Resampled S10_BVP from 351744 to 175872 points (64Hz to 32Hz)\n",
            "Resampled S10_EDA from 21984 to 175872 points (4Hz to 32Hz)\n",
            "Resampled S10_TEMP from 21984 to 175872 points (4Hz to 32Hz)\n",
            "Kept S11_ACC as is with 167456 points (at/near 32Hz or single row)\n",
            "Resampled S11_BVP from 334912 to 167456 points (64Hz to 32Hz)\n",
            "Resampled S11_EDA from 20932 to 167456 points (4Hz to 32Hz)\n",
            "Resampled S11_TEMP from 20932 to 167456 points (4Hz to 32Hz)\n",
            "\n",
            "Resampling complete.\n",
            "Creating df_event_timings from available df_s2_quest...\n",
            "df_event_timings created successfully.\n",
            "Aligned chest_S10_ACC\n",
            "Aligned chest_S10_ECG\n",
            "Aligned chest_S10_EMG\n",
            "Aligned chest_S10_EDA\n",
            "Aligned chest_S10_Temp\n",
            "Aligned chest_S10_Resp\n",
            "Aligned chest_S11_ACC\n",
            "Aligned chest_S11_ECG\n",
            "Aligned chest_S11_EMG\n",
            "Aligned chest_S11_EDA\n",
            "Aligned chest_S11_Temp\n",
            "Aligned chest_S11_Resp\n",
            "Aligned wrist_S10_ACC\n",
            "Aligned wrist_S10_BVP\n",
            "Aligned wrist_S10_EDA\n",
            "Aligned wrist_S10_TEMP\n",
            "Aligned wrist_S11_ACC\n",
            "Aligned wrist_S11_BVP\n",
            "Aligned wrist_S11_EDA\n",
            "Aligned wrist_S11_TEMP\n",
            "\n",
            "Alignment and Consolidation complete.\n",
            "Final DataFrame head:\n",
            "                        chest_S10_ACC_ACC_x  chest_S10_ACC_ACC_y  \\\n",
            "0 days 00:00:00                    0.899028             0.108722   \n",
            "0 days 00:00:00.031250             0.899520             0.046182   \n",
            "0 days 00:00:00.062500             0.907015             0.001234   \n",
            "0 days 00:00:00.093750             0.873405             0.076978   \n",
            "0 days 00:00:00.125000             0.860844             0.020315   \n",
            "\n",
            "                        chest_S10_ACC_ACC_z  chest_S10_ECG_ECG  \\\n",
            "0 days 00:00:00                   -0.252965          -1.333694   \n",
            "0 days 00:00:00.031250            -0.386988          -1.327744   \n",
            "0 days 00:00:00.062500            -0.217283          -1.322067   \n",
            "0 days 00:00:00.093750            -0.221324          -1.316345   \n",
            "0 days 00:00:00.125000            -0.206966          -1.310257   \n",
            "\n",
            "                        chest_S10_EMG_EMG  chest_S10_EDA_EDA  \\\n",
            "0 days 00:00:00                 -0.013687           0.716019   \n",
            "0 days 00:00:00.031250          -0.021927           0.714493   \n",
            "0 days 00:00:00.062500          -0.009018           0.715637   \n",
            "0 days 00:00:00.093750          -0.002380           0.714874   \n",
            "0 days 00:00:00.125000           0.001053           0.715256   \n",
            "\n",
            "                        chest_S10_Temp_Temp  chest_S10_Resp_Resp  \\\n",
            "0 days 00:00:00                   33.695862             0.213623   \n",
            "0 days 00:00:00.031250            33.741333             0.192261   \n",
            "0 days 00:00:00.062500            33.717072             0.205994   \n",
            "0 days 00:00:00.093750            33.741333             0.193787   \n",
            "0 days 00:00:00.125000            33.747406             0.172424   \n",
            "\n",
            "                        chest_S11_ACC_ACC_x  chest_S11_ACC_ACC_y  ...  \\\n",
            "0 days 00:00:00                    0.864597            -0.193985  ...   \n",
            "0 days 00:00:00.031250             0.967215            -0.439638  ...   \n",
            "0 days 00:00:00.062500             0.855331             0.091023  ...   \n",
            "0 days 00:00:00.093750             1.057255             0.076747  ...   \n",
            "0 days 00:00:00.125000             0.880183             0.156455  ...   \n",
            "\n",
            "                        wrist_S10_ACC_ACC_z  wrist_S10_BVP_BVP  \\\n",
            "0 days 00:00:00                       127.0          25.722862   \n",
            "0 days 00:00:00.031250                 45.0           8.799285   \n",
            "0 days 00:00:00.062500                  0.0          14.642219   \n",
            "0 days 00:00:00.093750                 46.0           7.799089   \n",
            "0 days 00:00:00.125000                 45.0           7.803862   \n",
            "\n",
            "                        wrist_S10_EDA_EDA  wrist_S10_TEMP_TEMP  \\\n",
            "0 days 00:00:00                  0.349215            33.130000   \n",
            "0 days 00:00:00.031250           0.305809            33.302211   \n",
            "0 days 00:00:00.062500           0.278123            33.412692   \n",
            "0 days 00:00:00.093750           0.265759            33.463091   \n",
            "0 days 00:00:00.125000           0.267049            33.460076   \n",
            "\n",
            "                        wrist_S11_ACC_ACC_x  wrist_S11_ACC_ACC_y  \\\n",
            "0 days 00:00:00                      -128.0                127.0   \n",
            "0 days 00:00:00.031250                -46.0                  2.0   \n",
            "0 days 00:00:00.062500                -82.0                -34.0   \n",
            "0 days 00:00:00.093750               -105.0                -19.0   \n",
            "0 days 00:00:00.125000                -72.0                 -8.0   \n",
            "\n",
            "                        wrist_S11_ACC_ACC_z  wrist_S11_BVP_BVP  \\\n",
            "0 days 00:00:00                       127.0          -6.899507   \n",
            "0 days 00:00:00.031250                 92.0          -1.899230   \n",
            "0 days 00:00:00.062500                  5.0           8.594355   \n",
            "0 days 00:00:00.093750                 11.0          11.732104   \n",
            "0 days 00:00:00.125000                 50.0          14.293105   \n",
            "\n",
            "                        wrist_S11_EDA_EDA  wrist_S11_TEMP_TEMP  \n",
            "0 days 00:00:00                  4.445500            34.000000  \n",
            "0 days 00:00:00.031250           4.682330            34.180678  \n",
            "0 days 00:00:00.062500           4.862431            34.294520  \n",
            "0 days 00:00:00.093750           4.983585            34.343623  \n",
            "0 days 00:00:00.125000           5.048162            34.335489  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "Final DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 641 entries, 0 days 00:00:00 to 0 days 00:00:20\n",
            "Data columns (total 28 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   chest_S10_ACC_ACC_x  641 non-null    float64\n",
            " 1   chest_S10_ACC_ACC_y  641 non-null    float64\n",
            " 2   chest_S10_ACC_ACC_z  641 non-null    float64\n",
            " 3   chest_S10_ECG_ECG    641 non-null    float64\n",
            " 4   chest_S10_EMG_EMG    641 non-null    float64\n",
            " 5   chest_S10_EDA_EDA    641 non-null    float64\n",
            " 6   chest_S10_Temp_Temp  641 non-null    float32\n",
            " 7   chest_S10_Resp_Resp  641 non-null    float64\n",
            " 8   chest_S11_ACC_ACC_x  641 non-null    float64\n",
            " 9   chest_S11_ACC_ACC_y  641 non-null    float64\n",
            " 10  chest_S11_ACC_ACC_z  641 non-null    float64\n",
            " 11  chest_S11_ECG_ECG    641 non-null    float64\n",
            " 12  chest_S11_EMG_EMG    641 non-null    float64\n",
            " 13  chest_S11_EDA_EDA    641 non-null    float64\n",
            " 14  chest_S11_Temp_Temp  641 non-null    float32\n",
            " 15  chest_S11_Resp_Resp  641 non-null    float64\n",
            " 16  wrist_S10_ACC_ACC_x  641 non-null    float64\n",
            " 17  wrist_S10_ACC_ACC_y  641 non-null    float64\n",
            " 18  wrist_S10_ACC_ACC_z  641 non-null    float64\n",
            " 19  wrist_S10_BVP_BVP    641 non-null    float64\n",
            " 20  wrist_S10_EDA_EDA    641 non-null    float64\n",
            " 21  wrist_S10_TEMP_TEMP  641 non-null    float64\n",
            " 22  wrist_S11_ACC_ACC_x  641 non-null    float64\n",
            " 23  wrist_S11_ACC_ACC_y  641 non-null    float64\n",
            " 24  wrist_S11_ACC_ACC_z  641 non-null    float64\n",
            " 25  wrist_S11_BVP_BVP    641 non-null    float64\n",
            " 26  wrist_S11_EDA_EDA    641 non-null    float64\n",
            " 27  wrist_S11_TEMP_TEMP  641 non-null    float64\n",
            "dtypes: float32(2), float64(26)\n",
            "memory usage: 140.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3687c834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e446d19-5e8d-4bfb-f6e3-dd12a4584dd3"
      },
      "source": [
        "print(\"--- Initial Data Inspection for Chest Sensor DataFrames ---\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    print(f\"\\n----- {sensor_name} Data (Chest) -----\")\n",
        "    print(f\"\\n{sensor_name}.head():\")\n",
        "    print(df.head())\n",
        "    print(f\"\\n{sensor_name}.info():\")\n",
        "    df.info()\n",
        "    print(f\"\\n{sensor_name}.describe():\")\n",
        "    print(df.describe())\n",
        "\n",
        "print(\"\\n--- Initial Data Inspection for Wrist Sensor DataFrames ---\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    print(f\"\\n----- {sensor_name} Data (Wrist) -----\")\n",
        "    print(f\"\\n{sensor_name}.head():\")\n",
        "    print(df.head())\n",
        "    print(f\"\\n{sensor_name}.info():\")\n",
        "    df.info()\n",
        "    print(f\"\\n{sensor_name}.describe():\")\n",
        "    print(df.describe())\n",
        "\n",
        "print(\"\\n--- Initial Data Inspection for Questionnaire Data (df_s2_quest) ---\")\n",
        "print(\"\\ndf_s2_quest.head():\")\n",
        "print(df_s2_quest.head())\n",
        "print(\"\\ndf_s2_quest.info():\")\n",
        "df_s2_quest.info()\n",
        "print(\"\\ndf_s2_quest.describe():\")\n",
        "print(df_s2_quest.describe())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initial Data Inspection for Chest Sensor DataFrames ---\n",
            "\n",
            "----- S10_ACC Data (Chest) -----\n",
            "\n",
            "S10_ACC.head():\n",
            "                            ACC_x   ACC_y   ACC_z\n",
            "0 days 00:00:00            1.1278  0.1520  0.3416\n",
            "0 days 00:00:00.001428571  1.0932  0.1888  0.2922\n",
            "0 days 00:00:00.002857143  1.0354  0.2094  0.1858\n",
            "0 days 00:00:00.004285714  0.9666  0.2118  0.0412\n",
            "0 days 00:00:00.005714286  0.8916  0.2040 -0.1228\n",
            "\n",
            "S10_ACC.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 0 days 01:31:35.998571429\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ACC_x   float64\n",
            " 1   ACC_y   float64\n",
            " 2   ACC_z   float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 117.4 MB\n",
            "\n",
            "S10_ACC.describe():\n",
            "              ACC_x         ACC_y         ACC_z\n",
            "count  3.847200e+06  3.847200e+06  3.847200e+06\n",
            "mean   8.118784e-01  7.224698e-03 -3.253975e-01\n",
            "std    1.041634e-01  6.156533e-02  2.849468e-01\n",
            "min    4.820000e-01 -4.310000e-01 -1.852000e+00\n",
            "25%    7.290000e-01 -4.060000e-02 -5.810000e-01\n",
            "50%    8.650000e-01  2.380002e-02 -3.080000e-01\n",
            "75%    8.961999e-01  4.180002e-02 -1.350000e-01\n",
            "max    1.476800e+00  4.808000e-01  1.533200e+00\n",
            "\n",
            "----- S10_ECG Data (Chest) -----\n",
            "\n",
            "S10_ECG.head():\n",
            "                             ECG\n",
            "0 days 00:00:00        -1.333694\n",
            "0 days 00:00:00.031250 -1.327744\n",
            "0 days 00:00:00.062500 -1.322067\n",
            "0 days 00:00:00.093750 -1.316345\n",
            "0 days 00:00:00.125000 -1.310257\n",
            "\n",
            "S10_ECG.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 1 days 09:23:44.968750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ECG     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 58.7 MB\n",
            "\n",
            "S10_ECG.describe():\n",
            "                ECG\n",
            "count  3.847200e+06\n",
            "mean   1.254331e-03\n",
            "std    1.497234e-01\n",
            "min   -1.460220e+00\n",
            "25%   -3.858948e-02\n",
            "50%    1.812744e-02\n",
            "75%    5.461121e-02\n",
            "max    1.478714e+00\n",
            "\n",
            "----- S10_EMG Data (Chest) -----\n",
            "\n",
            "S10_EMG.head():\n",
            "                             EMG\n",
            "0 days 00:00:00        -0.013687\n",
            "0 days 00:00:00.031250 -0.021927\n",
            "0 days 00:00:00.062500 -0.009018\n",
            "0 days 00:00:00.093750 -0.002380\n",
            "0 days 00:00:00.125000  0.001053\n",
            "\n",
            "S10_EMG.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 1 days 09:23:44.968750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   EMG     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 58.7 MB\n",
            "\n",
            "S10_EMG.describe():\n",
            "                EMG\n",
            "count  3.847200e+06\n",
            "mean  -2.561529e-03\n",
            "std    1.042374e-02\n",
            "min   -1.594391e-01\n",
            "25%   -8.468628e-03\n",
            "50%   -1.876831e-03\n",
            "75%    3.616333e-03\n",
            "max    1.421356e-01\n",
            "\n",
            "----- S10_EDA Data (Chest) -----\n",
            "\n",
            "S10_EDA.head():\n",
            "                             EDA\n",
            "0 days 00:00:00         0.716019\n",
            "0 days 00:00:00.031250  0.714493\n",
            "0 days 00:00:00.062500  0.715637\n",
            "0 days 00:00:00.093750  0.714874\n",
            "0 days 00:00:00.125000  0.715256\n",
            "\n",
            "S10_EDA.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 1 days 09:23:44.968750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   EDA     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 58.7 MB\n",
            "\n",
            "S10_EDA.describe():\n",
            "                EDA\n",
            "count  3.847200e+06\n",
            "mean   1.281778e+00\n",
            "std    4.552230e-01\n",
            "min    4.161835e-01\n",
            "25%    8.674622e-01\n",
            "50%    1.001740e+00\n",
            "75%    1.686859e+00\n",
            "max    2.257919e+00\n",
            "\n",
            "----- S10_Temp Data (Chest) -----\n",
            "\n",
            "S10_Temp.head():\n",
            "                             Temp\n",
            "0 days 00:00:00         33.695862\n",
            "0 days 00:00:00.031250  33.741333\n",
            "0 days 00:00:00.062500  33.717072\n",
            "0 days 00:00:00.093750  33.741333\n",
            "0 days 00:00:00.125000  33.747406\n",
            "\n",
            "S10_Temp.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 1 days 09:23:44.968750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   Temp    float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 44.0 MB\n",
            "\n",
            "S10_Temp.describe():\n",
            "               Temp\n",
            "count  3.847200e+06\n",
            "mean   3.477422e+01\n",
            "std    1.376595e+00\n",
            "min    3.365948e+01\n",
            "25%    3.438724e+01\n",
            "50%    3.461252e+01\n",
            "75%    3.526480e+01\n",
            "max    3.577805e+01\n",
            "\n",
            "----- S10_Resp Data (Chest) -----\n",
            "\n",
            "S10_Resp.head():\n",
            "                            Resp\n",
            "0 days 00:00:00         0.213623\n",
            "0 days 00:00:00.031250  0.192261\n",
            "0 days 00:00:00.062500  0.205994\n",
            "0 days 00:00:00.093750  0.193787\n",
            "0 days 00:00:00.125000  0.172424\n",
            "\n",
            "S10_Resp.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3847200 entries, 0 days 00:00:00 to 1 days 09:23:44.968750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   Resp    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 58.7 MB\n",
            "\n",
            "S10_Resp.describe():\n",
            "               Resp\n",
            "count  3.847200e+06\n",
            "mean   5.090375e-02\n",
            "std    3.450750e+00\n",
            "min   -2.693024e+01\n",
            "25%   -2.049255e+00\n",
            "50%   -2.288818e-01\n",
            "75%    2.058411e+00\n",
            "max    3.189545e+01\n",
            "\n",
            "----- S11_ACC Data (Chest) -----\n",
            "\n",
            "S11_ACC.head():\n",
            "                            ACC_x   ACC_y   ACC_z\n",
            "0 days 00:00:00            0.7674  0.4226  1.7662\n",
            "0 days 00:00:00.001428571  0.7326  0.2878  1.7234\n",
            "0 days 00:00:00.002857143  0.6894  0.1146  1.5550\n",
            "0 days 00:00:00.004285714  0.6646 -0.0626  1.3322\n",
            "0 days 00:00:00.005714286  0.6590 -0.2322  1.0834\n",
            "\n",
            "S11_ACC.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 0 days 01:27:12.998571429\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ACC_x   float64\n",
            " 1   ACC_y   float64\n",
            " 2   ACC_z   float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 111.8 MB\n",
            "\n",
            "S11_ACC.describe():\n",
            "              ACC_x         ACC_y         ACC_z\n",
            "count  3.663100e+06  3.663100e+06  3.663100e+06\n",
            "mean   8.834020e-01  1.275305e-02 -2.218108e-01\n",
            "std    2.590039e-02  5.353580e-02  1.100867e-01\n",
            "min    2.977999e-01 -8.262000e-01 -1.547000e+00\n",
            "25%    8.680000e-01 -1.220000e-02 -2.882000e-01\n",
            "50%    8.834000e-01  9.400010e-03 -2.406000e-01\n",
            "75%    8.980000e-01  4.240000e-02 -1.826000e-01\n",
            "max    2.037600e+00  4.994000e-01  2.610800e+00\n",
            "\n",
            "----- S11_ECG Data (Chest) -----\n",
            "\n",
            "S11_ECG.head():\n",
            "                             ECG\n",
            "0 days 00:00:00         0.020096\n",
            "0 days 00:00:00.031250  0.036850\n",
            "0 days 00:00:00.062500  0.053650\n",
            "0 days 00:00:00.093750  0.052780\n",
            "0 days 00:00:00.125000  0.035751\n",
            "\n",
            "S11_ECG.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 1 days 07:47:51.843750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ECG     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 55.9 MB\n",
            "\n",
            "S11_ECG.describe():\n",
            "                ECG\n",
            "count  3.663100e+06\n",
            "mean   1.054395e-03\n",
            "std    2.988793e-01\n",
            "min   -8.789520e-01\n",
            "25%   -1.128387e-01\n",
            "50%   -4.220581e-02\n",
            "75%    3.634644e-02\n",
            "max    1.499954e+00\n",
            "\n",
            "----- S11_EMG Data (Chest) -----\n",
            "\n",
            "S11_EMG.head():\n",
            "                             EMG\n",
            "0 days 00:00:00        -0.013870\n",
            "0 days 00:00:00.031250 -0.002014\n",
            "0 days 00:00:00.062500 -0.007599\n",
            "0 days 00:00:00.093750 -0.026505\n",
            "0 days 00:00:00.125000 -0.040421\n",
            "\n",
            "S11_EMG.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 1 days 07:47:51.843750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   EMG     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 55.9 MB\n",
            "\n",
            "S11_EMG.describe():\n",
            "                EMG\n",
            "count  3.663100e+06\n",
            "mean  -3.610395e-03\n",
            "std    1.317887e-02\n",
            "min   -3.598938e-01\n",
            "25%   -1.043701e-02\n",
            "50%   -3.479004e-03\n",
            "75%    3.158569e-03\n",
            "max    3.357239e-01\n",
            "\n",
            "----- S11_EDA Data (Chest) -----\n",
            "\n",
            "S11_EDA.head():\n",
            "                             EDA\n",
            "0 days 00:00:00         6.607437\n",
            "0 days 00:00:00.031250  6.603241\n",
            "0 days 00:00:00.062500  6.605530\n",
            "0 days 00:00:00.093750  6.611252\n",
            "0 days 00:00:00.125000  6.609726\n",
            "\n",
            "S11_EDA.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 1 days 07:47:51.843750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   EDA     float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 55.9 MB\n",
            "\n",
            "S11_EDA.describe():\n",
            "                EDA\n",
            "count  3.663100e+06\n",
            "mean   6.504319e+00\n",
            "std    4.213099e-01\n",
            "min    5.626297e+00\n",
            "25%    6.250000e+00\n",
            "50%    6.392288e+00\n",
            "75%    6.624985e+00\n",
            "max    8.166885e+00\n",
            "\n",
            "----- S11_Temp Data (Chest) -----\n",
            "\n",
            "S11_Temp.head():\n",
            "                             Temp\n",
            "0 days 00:00:00         33.520264\n",
            "0 days 00:00:00.031250  33.494537\n",
            "0 days 00:00:00.062500  33.508148\n",
            "0 days 00:00:00.093750  33.491516\n",
            "0 days 00:00:00.125000  33.524780\n",
            "\n",
            "S11_Temp.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 1 days 07:47:51.843750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   Temp    float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 41.9 MB\n",
            "\n",
            "S11_Temp.describe():\n",
            "               Temp\n",
            "count  3.663100e+06\n",
            "mean   3.468896e+01\n",
            "std    1.190299e+00\n",
            "min    3.343860e+01\n",
            "25%    3.454959e+01\n",
            "50%    3.468933e+01\n",
            "75%    3.496799e+01\n",
            "max    3.523849e+01\n",
            "\n",
            "----- S11_Resp Data (Chest) -----\n",
            "\n",
            "S11_Resp.head():\n",
            "                            Resp\n",
            "0 days 00:00:00         2.120972\n",
            "0 days 00:00:00.031250  2.113342\n",
            "0 days 00:00:00.062500  2.122498\n",
            "0 days 00:00:00.093750  2.125549\n",
            "0 days 00:00:00.125000  2.131653\n",
            "\n",
            "S11_Resp.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 3663100 entries, 0 days 00:00:00 to 1 days 07:47:51.843750\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   Resp    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 55.9 MB\n",
            "\n",
            "S11_Resp.describe():\n",
            "               Resp\n",
            "count  3.663100e+06\n",
            "mean   5.051829e-02\n",
            "std    4.815635e+00\n",
            "min   -3.619690e+01\n",
            "25%   -2.073669e+00\n",
            "50%   -7.629395e-02\n",
            "75%    2.253723e+00\n",
            "max    3.008423e+01\n",
            "\n",
            "--- Initial Data Inspection for Wrist Sensor DataFrames ---\n",
            "\n",
            "----- S10_ACC Data (Wrist) -----\n",
            "\n",
            "S10_ACC.head():\n",
            "                        ACC_x  ACC_y  ACC_z\n",
            "0 days 00:00:00         107.0 -105.0  127.0\n",
            "0 days 00:00:00.031250   67.0  -52.0   45.0\n",
            "0 days 00:00:00.062500   26.0   40.0    0.0\n",
            "0 days 00:00:00.093750   52.0   12.0   46.0\n",
            "0 days 00:00:00.125000   42.0   20.0   45.0\n",
            "\n",
            "S10_ACC.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 175872 entries, 0 days 00:00:00 to 0 days 01:31:35.968750\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   ACC_x   175872 non-null  float64\n",
            " 1   ACC_y   175872 non-null  float64\n",
            " 2   ACC_z   175872 non-null  float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 5.4 MB\n",
            "\n",
            "S10_ACC.describe():\n",
            "               ACC_x         ACC_y          ACC_z\n",
            "count  175872.000000  175872.00000  175872.000000\n",
            "mean       42.882437      -1.07199      17.579854\n",
            "std        18.481615      21.96079      32.024483\n",
            "min       -74.000000    -128.00000     -96.000000\n",
            "25%        26.000000     -17.00000     -12.000000\n",
            "50%        48.000000       3.00000      12.000000\n",
            "75%        59.000000       8.00000      53.000000\n",
            "max       127.000000      80.00000     127.000000\n",
            "\n",
            "----- S10_BVP Data (Wrist) -----\n",
            "\n",
            "S10_BVP.head():\n",
            "                          BVP\n",
            "0 days 00:00:00         10.17\n",
            "0 days 00:00:00.015625  12.04\n",
            "0 days 00:00:00.031250  13.01\n",
            "0 days 00:00:00.046875  13.07\n",
            "0 days 00:00:00.062500  12.33\n",
            "\n",
            "S10_BVP.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 351744 entries, 0 days 00:00:00 to 0 days 01:31:35.984375\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   BVP     351744 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 5.4 MB\n",
            "\n",
            "S10_BVP.describe():\n",
            "                 BVP\n",
            "count  351744.000000\n",
            "mean        0.000452\n",
            "std        46.252525\n",
            "min      -609.230000\n",
            "25%       -12.360000\n",
            "50%         2.530000\n",
            "75%        12.740000\n",
            "max       779.690000\n",
            "\n",
            "----- S10_EDA Data (Wrist) -----\n",
            "\n",
            "S10_EDA.head():\n",
            "                             EDA\n",
            "0 days 00:00:00         0.349215\n",
            "0 days 00:00:00.250000  0.346656\n",
            "0 days 00:00:00.500000  0.350494\n",
            "0 days 00:00:00.750000  0.336423\n",
            "0 days 00:00:01         0.338981\n",
            "\n",
            "S10_EDA.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 21984 entries, 0 days 00:00:00 to 0 days 01:31:35.750000\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     21984 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 343.5 KB\n",
            "\n",
            "S10_EDA.describe():\n",
            "                EDA\n",
            "count  21984.000000\n",
            "mean       0.981519\n",
            "std        0.766773\n",
            "min        0.266335\n",
            "25%        0.418290\n",
            "50%        0.472282\n",
            "75%        1.371709\n",
            "max        3.507541\n",
            "\n",
            "----- S10_TEMP Data (Wrist) -----\n",
            "\n",
            "S10_TEMP.head():\n",
            "                         TEMP\n",
            "0 days 00:00:00         33.13\n",
            "0 days 00:00:00.250000  33.16\n",
            "0 days 00:00:00.500000  33.16\n",
            "0 days 00:00:00.750000  33.16\n",
            "0 days 00:00:01         33.16\n",
            "\n",
            "S10_TEMP.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 21984 entries, 0 days 00:00:00 to 0 days 01:31:35.750000\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   TEMP    21984 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 343.5 KB\n",
            "\n",
            "S10_TEMP.describe():\n",
            "               TEMP\n",
            "count  21984.000000\n",
            "mean      33.430048\n",
            "std        0.971530\n",
            "min       30.810000\n",
            "25%       32.930000\n",
            "50%       33.660000\n",
            "75%       34.180000\n",
            "max       34.710000\n",
            "\n",
            "----- S11_ACC Data (Wrist) -----\n",
            "\n",
            "S11_ACC.head():\n",
            "                        ACC_x  ACC_y  ACC_z\n",
            "0 days 00:00:00        -128.0  127.0  127.0\n",
            "0 days 00:00:00.031250  -46.0    2.0   92.0\n",
            "0 days 00:00:00.062500  -82.0  -34.0    5.0\n",
            "0 days 00:00:00.093750 -105.0  -19.0   11.0\n",
            "0 days 00:00:00.125000  -72.0   -8.0   50.0\n",
            "\n",
            "S11_ACC.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 167456 entries, 0 days 00:00:00 to 0 days 01:27:12.968750\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   ACC_x   167456 non-null  float64\n",
            " 1   ACC_y   167456 non-null  float64\n",
            " 2   ACC_z   167456 non-null  float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 5.1 MB\n",
            "\n",
            "S11_ACC.describe():\n",
            "               ACC_x          ACC_y          ACC_z\n",
            "count  167456.000000  167456.000000  167456.000000\n",
            "mean      -44.225152      -2.322353       9.846133\n",
            "std        20.657688      25.101795      33.165506\n",
            "min      -128.000000     -89.000000    -128.000000\n",
            "25%       -59.000000     -20.000000     -14.000000\n",
            "50%       -51.000000      -1.000000      17.000000\n",
            "75%       -39.000000      18.000000      38.000000\n",
            "max       108.000000     127.000000     127.000000\n",
            "\n",
            "----- S11_BVP Data (Wrist) -----\n",
            "\n",
            "S11_BVP.head():\n",
            "                          BVP\n",
            "0 days 00:00:00        -12.14\n",
            "0 days 00:00:00.015625  -6.20\n",
            "0 days 00:00:00.031250  -0.58\n",
            "0 days 00:00:00.046875   4.20\n",
            "0 days 00:00:00.062500   7.89\n",
            "\n",
            "S11_BVP.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 334912 entries, 0 days 00:00:00 to 0 days 01:27:12.984375\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   BVP     334912 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 5.1 MB\n",
            "\n",
            "S11_BVP.describe():\n",
            "                 BVP\n",
            "count  334912.000000\n",
            "mean        0.001623\n",
            "std        42.018479\n",
            "min      -561.910000\n",
            "25%        -8.860000\n",
            "50%         1.390000\n",
            "75%        11.680000\n",
            "max       630.130000\n",
            "\n",
            "----- S11_EDA Data (Wrist) -----\n",
            "\n",
            "S11_EDA.head():\n",
            "                             EDA\n",
            "0 days 00:00:00         4.445500\n",
            "0 days 00:00:00.250000  4.911148\n",
            "0 days 00:00:00.500000  4.741007\n",
            "0 days 00:00:00.750000  4.950804\n",
            "0 days 00:00:01         4.900373\n",
            "\n",
            "S11_EDA.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 20932 entries, 0 days 00:00:00 to 0 days 01:27:12.750000\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     20932 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 327.1 KB\n",
            "\n",
            "S11_EDA.describe():\n",
            "                EDA\n",
            "count  20932.000000\n",
            "mean       3.184846\n",
            "std        0.855296\n",
            "min        1.842755\n",
            "25%        2.559895\n",
            "50%        2.910715\n",
            "75%        3.463298\n",
            "max        6.095525\n",
            "\n",
            "----- S11_TEMP Data (Wrist) -----\n",
            "\n",
            "S11_TEMP.head():\n",
            "                         TEMP\n",
            "0 days 00:00:00         34.00\n",
            "0 days 00:00:00.250000  34.00\n",
            "0 days 00:00:00.500000  34.00\n",
            "0 days 00:00:00.750000  34.00\n",
            "0 days 00:00:01         34.03\n",
            "\n",
            "S11_TEMP.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "TimedeltaIndex: 20932 entries, 0 days 00:00:00 to 0 days 01:27:12.750000\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   TEMP    20932 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 327.1 KB\n",
            "\n",
            "S11_TEMP.describe():\n",
            "               TEMP\n",
            "count  20932.000000\n",
            "mean      32.836507\n",
            "std        1.167587\n",
            "min       31.430000\n",
            "25%       31.670000\n",
            "50%       32.490000\n",
            "75%       34.110000\n",
            "max       34.470000\n",
            "\n",
            "--- Initial Data Inspection for Questionnaire Data (df_s2_quest) ---\n",
            "\n",
            "df_s2_quest.head():\n",
            "                 # Subj;S10;;;;;;;;;;;;;;;;;;;;;;;;;\n",
            "0  # ORDER;Base;Fun;Medi 1;TSST;Medi 2;bRead;fRea...\n",
            "1  # START;2.5;27.53;38.42;54.3;83.17;23.39;34.58...\n",
            "2  # END;22.5;34.25;45.4;66.55;90.15;24.5;36.15;7...\n",
            "3                         ;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
            "4  # PANAS;2;1;3;1;1;1;1;1;1;2;1;1;2;1;3;2;1;2;1;...\n",
            "\n",
            "df_s2_quest.info():\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23 entries, 0 to 22\n",
            "Data columns (total 1 columns):\n",
            " #   Column                               Non-Null Count  Dtype \n",
            "---  ------                               --------------  ----- \n",
            " 0   # Subj;S10;;;;;;;;;;;;;;;;;;;;;;;;;  23 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 316.0+ bytes\n",
            "\n",
            "df_s2_quest.describe():\n",
            "       # Subj;S10;;;;;;;;;;;;;;;;;;;;;;;;;\n",
            "count                                   23\n",
            "unique                                  19\n",
            "top             ;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
            "freq                                     4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68f3c6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f837548a-5be2-4056-e817-9cd3d094ed91"
      },
      "source": [
        "print(\"--- Checking for Missing Values in Chest Sensor DataFrames ---\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    print(f\"\\nMissing values in {sensor_name} (Chest):\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Checking for Missing Values in Wrist Sensor DataFrames ---\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    print(f\"\\nMissing values in {sensor_name} (Wrist):\")\n",
        "    print(df.isnull().sum())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking for Missing Values in Chest Sensor DataFrames ---\n",
            "\n",
            "Missing values in S10_ACC (Chest):\n",
            "ACC_x    0\n",
            "ACC_y    0\n",
            "ACC_z    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_ECG (Chest):\n",
            "ECG    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_EMG (Chest):\n",
            "EMG    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_EDA (Chest):\n",
            "EDA    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_Temp (Chest):\n",
            "Temp    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_Resp (Chest):\n",
            "Resp    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_ACC (Chest):\n",
            "ACC_x    0\n",
            "ACC_y    0\n",
            "ACC_z    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_ECG (Chest):\n",
            "ECG    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_EMG (Chest):\n",
            "EMG    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_EDA (Chest):\n",
            "EDA    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_Temp (Chest):\n",
            "Temp    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_Resp (Chest):\n",
            "Resp    0\n",
            "dtype: int64\n",
            "\n",
            "--- Checking for Missing Values in Wrist Sensor DataFrames ---\n",
            "\n",
            "Missing values in S10_ACC (Wrist):\n",
            "ACC_x    0\n",
            "ACC_y    0\n",
            "ACC_z    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_BVP (Wrist):\n",
            "BVP    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_EDA (Wrist):\n",
            "EDA    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S10_TEMP (Wrist):\n",
            "TEMP    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_ACC (Wrist):\n",
            "ACC_x    0\n",
            "ACC_y    0\n",
            "ACC_z    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_BVP (Wrist):\n",
            "BVP    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_EDA (Wrist):\n",
            "EDA    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in S11_TEMP (Wrist):\n",
            "TEMP    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38cd41c5"
      },
      "source": [
        "```markdown\n",
        "**Regarding `df_s2_quest`:**\n",
        "\n",
        "The `df_s2_quest` DataFrame is not yet in a tabular format suitable for a direct `.isnull().sum()` check. It contains metadata and questionnaire responses within a few rows, separated by semicolons. This DataFrame will require further parsing and cleaning before a meaningful assessment of missing values can be performed for individual questions/fields.\n",
        "\n",
        "Based on the current state of the chest and wrist sensor data, there are no missing values detected.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3df1e040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017cfdde-06f9-4dae-a907-890142a87428"
      },
      "source": [
        "print(\"--- Checking for Duplicate Rows in Chest Sensor DataFrames ---\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    print(f\"\\nDuplicate rows in {sensor_name} (Chest): {df.duplicated().sum()}\")\n",
        "\n",
        "print(\"\\n--- Checking for Duplicate Rows in Wrist Sensor DataFrames ---\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    print(f\"\\nDuplicate rows in {sensor_name} (Wrist): {df.duplicated().sum()}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking for Duplicate Rows in Chest Sensor DataFrames ---\n",
            "\n",
            "Duplicate rows in S10_ACC (Chest): 438378\n",
            "\n",
            "Duplicate rows in S10_ECG (Chest): 3811308\n",
            "\n",
            "Duplicate rows in S10_EMG (Chest): 3843618\n",
            "\n",
            "Duplicate rows in S10_EDA (Chest): 3843223\n",
            "\n",
            "Duplicate rows in S10_Temp (Chest): 3845838\n",
            "\n",
            "Duplicate rows in S10_Resp (Chest): 3821943\n",
            "\n",
            "Duplicate rows in S11_ACC (Chest): 226347\n",
            "\n",
            "Duplicate rows in S11_ECG (Chest): 3619629\n",
            "\n",
            "Duplicate rows in S11_EMG (Chest): 3657691\n",
            "\n",
            "Duplicate rows in S11_EDA (Chest): 3657257\n",
            "\n",
            "Duplicate rows in S11_Temp (Chest): 3661934\n",
            "\n",
            "Duplicate rows in S11_Resp (Chest): 3628884\n",
            "\n",
            "--- Checking for Duplicate Rows in Wrist Sensor DataFrames ---\n",
            "\n",
            "Duplicate rows in S10_ACC (Wrist): 153183\n",
            "\n",
            "Duplicate rows in S10_BVP (Wrist): 320525\n",
            "\n",
            "Duplicate rows in S10_EDA (Wrist): 19280\n",
            "\n",
            "Duplicate rows in S10_TEMP (Wrist): 21788\n",
            "\n",
            "Duplicate rows in S11_ACC (Wrist): 130477\n",
            "\n",
            "Duplicate rows in S11_BVP (Wrist): 306518\n",
            "\n",
            "Duplicate rows in S11_EDA (Wrist): 17566\n",
            "\n",
            "Duplicate rows in S11_TEMP (Wrist): 20779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d5b5d32"
      },
      "source": [
        "```markdown\n",
        "**Regarding `df_s2_quest`:**\n",
        "\n",
        "The `df_s2_quest` DataFrame is not yet in a tabular format suitable for a direct `.duplicated().sum()` check. It contains metadata and questionnaire responses within a few rows, separated by semicolons. This DataFrame will require further parsing and cleaning before a meaningful assessment of duplicate rows can be performed for individual questions/fields.\n",
        "\n",
        "**Regarding Sensor DataFrames:**\n",
        "\n",
        "Many of the chest and wrist sensor DataFrames contain a significant number of duplicate rows. This will need to be addressed in the next step to ensure data integrity and prevent skewed analysis.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f37cf66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7269b6c7-17f8-4e87-9e71-adad99293506"
      },
      "source": [
        "print(\"--- Removing Duplicate Rows from Chest Sensor DataFrames ---\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    initial_duplicates = df.duplicated().sum()\n",
        "    if initial_duplicates > 0:\n",
        "        chest_dataframes[sensor_name] = df.drop_duplicates().reset_index(drop=True)\n",
        "        print(f\"Removed {initial_duplicates} duplicate rows from {sensor_name} (Chest). New count: {chest_dataframes[sensor_name].duplicated().sum()}\")\n",
        "    else:\n",
        "        print(f\"No duplicate rows found in {sensor_name} (Chest).\")\n",
        "\n",
        "print(\"\\n--- Removing Duplicate Rows from Wrist Sensor DataFrames ---\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    initial_duplicates = df.duplicated().sum()\n",
        "    if initial_duplicates > 0:\n",
        "        wrist_dataframes[sensor_name] = df.drop_duplicates().reset_index(drop=True)\n",
        "        print(f\"Removed {initial_duplicates} duplicate rows from {sensor_name} (Wrist). New count: {wrist_dataframes[sensor_name].duplicated().sum()}\")\n",
        "    else:\n",
        "        print(f\"No duplicate rows found in {sensor_name} (Wrist).\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Removing Duplicate Rows from Chest Sensor DataFrames ---\n",
            "Removed 438378 duplicate rows from S10_ACC (Chest). New count: 0\n",
            "Removed 3811308 duplicate rows from S10_ECG (Chest). New count: 0\n",
            "Removed 3843618 duplicate rows from S10_EMG (Chest). New count: 0\n",
            "Removed 3843223 duplicate rows from S10_EDA (Chest). New count: 0\n",
            "Removed 3845838 duplicate rows from S10_Temp (Chest). New count: 0\n",
            "Removed 3821943 duplicate rows from S10_Resp (Chest). New count: 0\n",
            "Removed 226347 duplicate rows from S11_ACC (Chest). New count: 0\n",
            "Removed 3619629 duplicate rows from S11_ECG (Chest). New count: 0\n",
            "Removed 3657691 duplicate rows from S11_EMG (Chest). New count: 0\n",
            "Removed 3657257 duplicate rows from S11_EDA (Chest). New count: 0\n",
            "Removed 3661934 duplicate rows from S11_Temp (Chest). New count: 0\n",
            "Removed 3628884 duplicate rows from S11_Resp (Chest). New count: 0\n",
            "\n",
            "--- Removing Duplicate Rows from Wrist Sensor DataFrames ---\n",
            "Removed 153183 duplicate rows from S10_ACC (Wrist). New count: 0\n",
            "Removed 320525 duplicate rows from S10_BVP (Wrist). New count: 0\n",
            "Removed 19280 duplicate rows from S10_EDA (Wrist). New count: 0\n",
            "Removed 21788 duplicate rows from S10_TEMP (Wrist). New count: 0\n",
            "Removed 130477 duplicate rows from S11_ACC (Wrist). New count: 0\n",
            "Removed 306518 duplicate rows from S11_BVP (Wrist). New count: 0\n",
            "Removed 17566 duplicate rows from S11_EDA (Wrist). New count: 0\n",
            "Removed 20779 duplicate rows from S11_TEMP (Wrist). New count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf215c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9b15a6-2ce9-4e87-efec-0204a032e357"
      },
      "source": [
        "print(\"--- Checking Data Types for Chest Sensor DataFrames ---\")\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    print(f\"\\n----- {sensor_name} Data (Chest) -----\")\n",
        "    df.info()\n",
        "\n",
        "print(\"\\n--- Checking Data Types for Wrist Sensor DataFrames ---\")\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    print(f\"\\n----- {sensor_name} Data (Wrist) -----\")\n",
        "    df.info()\n",
        "\n",
        "print(\"\\n--- Checking Data Types for Questionnaire Data (df_s2_quest) ---\")\n",
        "df_s2_quest.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking Data Types for Chest Sensor DataFrames ---\n",
            "\n",
            "----- S10_ACC Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3408822 entries, 0 to 3408821\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ACC_x   float64\n",
            " 1   ACC_y   float64\n",
            " 2   ACC_z   float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 78.0 MB\n",
            "\n",
            "----- S10_ECG Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35892 entries, 0 to 35891\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   ECG     35892 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 280.5 KB\n",
            "\n",
            "----- S10_EMG Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3582 entries, 0 to 3581\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EMG     3582 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 28.1 KB\n",
            "\n",
            "----- S10_EDA Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3977 entries, 0 to 3976\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     3977 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 31.2 KB\n",
            "\n",
            "----- S10_Temp Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1362 entries, 0 to 1361\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Temp    1362 non-null   float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 5.4 KB\n",
            "\n",
            "----- S10_Resp Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25257 entries, 0 to 25256\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Resp    25257 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 197.4 KB\n",
            "\n",
            "----- S11_ACC Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3436753 entries, 0 to 3436752\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   ACC_x   float64\n",
            " 1   ACC_y   float64\n",
            " 2   ACC_z   float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 78.7 MB\n",
            "\n",
            "----- S11_ECG Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43471 entries, 0 to 43470\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   ECG     43471 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 339.7 KB\n",
            "\n",
            "----- S11_EMG Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5409 entries, 0 to 5408\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EMG     5409 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 42.4 KB\n",
            "\n",
            "----- S11_EDA Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5843 entries, 0 to 5842\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     5843 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 45.8 KB\n",
            "\n",
            "----- S11_Temp Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1166 entries, 0 to 1165\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Temp    1166 non-null   float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 4.7 KB\n",
            "\n",
            "----- S11_Resp Data (Chest) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34216 entries, 0 to 34215\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Resp    34216 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 267.4 KB\n",
            "\n",
            "--- Checking Data Types for Wrist Sensor DataFrames ---\n",
            "\n",
            "----- S10_ACC Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22689 entries, 0 to 22688\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   ACC_x   22689 non-null  float64\n",
            " 1   ACC_y   22689 non-null  float64\n",
            " 2   ACC_z   22689 non-null  float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 531.9 KB\n",
            "\n",
            "----- S10_BVP Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31219 entries, 0 to 31218\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   BVP     31219 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 244.0 KB\n",
            "\n",
            "----- S10_EDA Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2704 entries, 0 to 2703\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     2704 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 21.3 KB\n",
            "\n",
            "----- S10_TEMP Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 196 entries, 0 to 195\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   TEMP    196 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 1.7 KB\n",
            "\n",
            "----- S11_ACC Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 36979 entries, 0 to 36978\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   ACC_x   36979 non-null  float64\n",
            " 1   ACC_y   36979 non-null  float64\n",
            " 2   ACC_z   36979 non-null  float64\n",
            "dtypes: float64(3)\n",
            "memory usage: 866.8 KB\n",
            "\n",
            "----- S11_BVP Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 28394 entries, 0 to 28393\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   BVP     28394 non-null  float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 222.0 KB\n",
            "\n",
            "----- S11_EDA Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3366 entries, 0 to 3365\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   EDA     3366 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 26.4 KB\n",
            "\n",
            "----- S11_TEMP Data (Wrist) -----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 153 entries, 0 to 152\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   TEMP    153 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 1.3 KB\n",
            "\n",
            "--- Checking Data Types for Questionnaire Data (df_s2_quest) ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23 entries, 0 to 22\n",
            "Data columns (total 1 columns):\n",
            " #   Column                               Non-Null Count  Dtype \n",
            "---  ------                               --------------  ----- \n",
            " 0   # Subj;S10;;;;;;;;;;;;;;;;;;;;;;;;;  23 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 316.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "875bf236"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the directory to save cleaned data\n",
        "cleaned_data_dir = f'{s2_data_path}/cleaned_data'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(cleaned_data_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Saving cleaned data to: {cleaned_data_dir}\")\n",
        "\n",
        "# Save df_event_timings\n",
        "df_event_timings.to_csv(f'{cleaned_data_dir}/df_event_timings.csv', index=False)\n",
        "print(\"Saved df_event_timings.csv\")\n",
        "\n",
        "# Save df_questionnaire_responses\n",
        "df_questionnaire_responses.to_csv(f'{cleaned_data_dir}/df_questionnaire_responses.csv', index=False)\n",
        "print(\"Saved df_questionnaire_responses.csv\")\n",
        "\n",
        "# Save individual chest sensor DataFrames\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    df.to_csv(f'{cleaned_data_dir}/chest_{sensor_name.lower()}.csv', index=False)\n",
        "    print(f\"Saved chest_{sensor_name.lower()}.csv\")\n",
        "\n",
        "# Save individual wrist sensor DataFrames\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    df.to_csv(f'{cleaned_data_dir}/wrist_{sensor_name.lower()}.csv', index=False)\n",
        "    print(f\"Saved wrist_{sensor_name.lower()}.csv\")\n",
        "\n",
        "print(\"All cleaned DataFrames saved successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace49612"
      },
      "source": [
        "print(\"--- Displaying all rows of df_s2_quest ---\")\n",
        "print(df_s2_quest.to_string())\n",
        "\n",
        "print(\"\\n--- First row of df_s2_quest ---\")\n",
        "print(df_s2_quest.iloc[0])\n",
        "\n",
        "print(\"\\n--- Second row of df_s2_quest ---\")\n",
        "print(df_s2_quest.iloc[1])\n",
        "\n",
        "print(\"\\n--- Third row of df_s2_quest ---\")\n",
        "print(df_s2_quest.iloc[2])\n",
        "\n",
        "print(\"\\n--- Fifth row of df_s2_quest (index 4) ---\")\n",
        "print(df_s2_quest.iloc[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f76da6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e732df8-8b24-41ba-fdb3-c4fbdd17d72c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Locate and extract the string content from the relevant rows\n",
        "order_str = df_s2_quest.iloc[0, 0]\n",
        "start_str = df_s2_quest.iloc[1, 0]\n",
        "end_str = df_s2_quest.iloc[2, 0]\n",
        "\n",
        "# 2. Split by semicolon and clean the lists\n",
        "# Remove empty strings and the initial '#' from the first element\n",
        "\n",
        "def clean_split_list(s):\n",
        "    # Remove the first '#' if present and split\n",
        "    parts = s.replace('#', '').split(';')\n",
        "    # Filter out empty strings\n",
        "    return [p.strip() for p in parts if p.strip()]\n",
        "\n",
        "cleaned_order = clean_split_list(order_str)\n",
        "cleaned_start = clean_split_list(start_str)\n",
        "cleaned_end = clean_split_list(end_str)\n",
        "\n",
        "# 3. Create a list of event names (skipping the 'ORDER' label)\n",
        "event_names = cleaned_order[1:]\n",
        "\n",
        "# 4. Create dictionaries for START and END times, converting to float\n",
        "start_times = {}\n",
        "for i, event in enumerate(event_names):\n",
        "    # Ensure index is within bounds for start_str data, skipping the 'START' label\n",
        "    if (i + 1) < len(cleaned_start):\n",
        "        try:\n",
        "            start_times[event] = float(cleaned_start[i + 1])\n",
        "        except ValueError:\n",
        "            start_times[event] = None # Handle cases where conversion to float fails\n",
        "\n",
        "end_times = {}\n",
        "for i, event in enumerate(event_names):\n",
        "    # Ensure index is within bounds for end_str data, skipping the 'END' label\n",
        "    if (i + 1) < len(cleaned_end):\n",
        "        try:\n",
        "            end_times[event] = float(cleaned_end[i + 1])\n",
        "        except ValueError:\n",
        "            end_times[event] = None # Handle cases where conversion to float fails\n",
        "\n",
        "# 5. Combine into a new pandas DataFrame\n",
        "# Create lists for DataFrame construction\n",
        "events_list = []\n",
        "start_time_list = []\n",
        "end_time_list = []\n",
        "\n",
        "for event in event_names:\n",
        "    events_list.append(event)\n",
        "    start_time_list.append(start_times.get(event))\n",
        "    end_time_list.append(end_times.get(event))\n",
        "\n",
        "df_event_timings = pd.DataFrame({\n",
        "    'Event': events_list,\n",
        "    'Start_Time': start_time_list,\n",
        "    'End_Time': end_time_list\n",
        "})\n",
        "\n",
        "print(\"Event Timings DataFrame:\")\n",
        "print(df_event_timings)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event Timings DataFrame:\n",
            "    Event  Start_Time  End_Time\n",
            "0    Base        2.50     22.50\n",
            "1     Fun       27.53     34.25\n",
            "2  Medi 1       38.42     45.40\n",
            "3    TSST       54.30     66.55\n",
            "4  Medi 2       83.17     90.15\n",
            "5   bRead       23.39     24.50\n",
            "6   fRead       34.58     36.15\n",
            "7   sRead       71.22     72.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0ee8355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1abd4c-d2e5-4848-bf58-5dc3ad7cd9ca"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize empty lists to store parsed responses for each questionnaire type\n",
        "panas_data = []\n",
        "stai_data = []\n",
        "dim_data = []\n",
        "sssq_data = []\n",
        "\n",
        "# Iterate through df_s2_quest from row index 4 onwards (as metadata is already extracted)\n",
        "for i in range(4, len(df_s2_quest)):\n",
        "    row_string = df_s2_quest.iloc[i, 0]\n",
        "\n",
        "    # Check if the row starts with a questionnaire identifier and process it\n",
        "    if row_string.startswith('# PANAS'):\n",
        "        # Remove the tag and split by semicolon, then convert to numeric\n",
        "        parts = row_string.replace('# PANAS;', '').split(';')\n",
        "        numeric_parts = [float(p.strip()) for p in parts if p.strip()]\n",
        "        if numeric_parts:\n",
        "            panas_data.append(numeric_parts)\n",
        "    elif row_string.startswith('# STAI'):\n",
        "        parts = row_string.replace('# STAI;', '').split(';')\n",
        "        numeric_parts = [float(p.strip()) for p in parts if p.strip()]\n",
        "        if numeric_parts:\n",
        "            stai_data.append(numeric_parts)\n",
        "    elif row_string.startswith('# DIM'):\n",
        "        parts = row_string.replace('# DIM;', '').split(';')\n",
        "        numeric_parts = [float(p.strip()) for p in parts if p.strip()]\n",
        "        if numeric_parts:\n",
        "            dim_data.append(numeric_parts)\n",
        "    elif row_string.startswith('# SSSQ'):\n",
        "        parts = row_string.replace('# SSSQ;', '').split(';')\n",
        "        numeric_parts = [float(p.strip()) for p in parts if p.strip()]\n",
        "        if numeric_parts:\n",
        "            sssq_data.append(numeric_parts)\n",
        "\n",
        "# Convert lists of lists to pandas DataFrames. pd.DataFrame handles varying row lengths by padding with NaN.\n",
        "df_panas = pd.DataFrame(panas_data)\n",
        "df_stai = pd.DataFrame(stai_data)\n",
        "df_dim = pd.DataFrame(dim_data)\n",
        "df_sssq = pd.DataFrame(sssq_data)\n",
        "\n",
        "# Print the head of each created DataFrame to inspect the parsed questionnaire responses\n",
        "print(\"\\n--- df_panas head ---\")\n",
        "print(df_panas.head())\n",
        "\n",
        "print(\"\\n--- df_stai head ---\")\n",
        "print(df_stai.head())\n",
        "\n",
        "print(\"\\n--- df_dim head ---\")\n",
        "print(df_dim.head())\n",
        "\n",
        "print(\"\\n--- df_sssq head ---\")\n",
        "print(df_sssq.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- df_panas head ---\n",
            "    0    1    2    3    4    5    6    7    8    9   ...   16   17   18   19  \\\n",
            "0  2.0  1.0  3.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  ...  1.0  2.0  1.0  1.0   \n",
            "1  2.0  1.0  3.0  4.0  1.0  2.0  1.0  1.0  1.0  3.0  ...  2.0  4.0  1.0  1.0   \n",
            "2  1.0  1.0  2.0  2.0  1.0  1.0  1.0  1.0  1.0  2.0  ...  1.0  2.0  1.0  1.0   \n",
            "3  4.0  4.0  3.0  1.0  3.0  1.0  1.0  4.0  2.0  4.0  ...  1.0  4.0  4.0  2.0   \n",
            "4  2.0  2.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  ...  1.0  2.0  1.0  1.0   \n",
            "\n",
            "    20   21   22   23   24   25  \n",
            "0  1.0  1.0  2.0  1.0  NaN  NaN  \n",
            "1  1.0  1.0  4.0  1.0  NaN  NaN  \n",
            "2  1.0  1.0  2.0  1.0  NaN  NaN  \n",
            "3  4.0  3.0  1.0  2.0  3.0  1.0  \n",
            "4  2.0  1.0  2.0  1.0  NaN  NaN  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "\n",
            "--- df_stai head ---\n",
            "     0    1    2    3    4    5\n",
            "0  3.0  2.0  1.0  3.0  1.0  2.0\n",
            "1  3.0  1.0  1.0  3.0  1.0  4.0\n",
            "2  4.0  1.0  1.0  3.0  1.0  1.0\n",
            "3  1.0  4.0  2.0  1.0  2.0  1.0\n",
            "4  3.0  2.0  1.0  3.0  1.0  1.0\n",
            "\n",
            "--- df_dim head ---\n",
            "     0    1\n",
            "0  6.0  2.0\n",
            "1  8.0  2.0\n",
            "2  6.0  1.0\n",
            "3  3.0  8.0\n",
            "4  6.0  2.0\n",
            "\n",
            "--- df_sssq head ---\n",
            "     0    1    2    3    4    5\n",
            "0  3.0  2.0  2.0  3.0  3.0  2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a24052b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee17f1a-e37a-41e1-8aa5-4d50baaf1f80"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Rename the columns of each DataFrame\n",
        "df_panas.columns = [f'PANAS_{i}' for i in range(len(df_panas.columns))]\n",
        "df_stai.columns = [f'STAI_{i}' for i in range(len(df_stai.columns))]\n",
        "df_dim.columns = [f'DIM_{i}' for i in range(len(df_dim.columns))]\n",
        "df_sssq.columns = [f'SSSQ_{i}' for i in range(len(df_sssq.columns))]\n",
        "\n",
        "# 2. Concatenate df_panas, df_stai, and df_dim horizontally\n",
        "df_combined_responses = pd.concat([df_panas, df_stai, df_dim], axis=1)\n",
        "\n",
        "# 3. Create a new DataFrame for df_sssq with the same number of rows as df_combined_responses\n",
        "# Get the number of rows from df_combined_responses\n",
        "num_rows = len(df_combined_responses)\n",
        "\n",
        "# Create an empty DataFrame with the correct number of rows and columns from df_sssq\n",
        "df_sssq_extended = pd.DataFrame(np.nan, index=range(num_rows), columns=df_sssq.columns)\n",
        "\n",
        "# Place the actual df_sssq data (which is a single row) into the first row of the extended DataFrame\n",
        "if not df_sssq.empty:\n",
        "    df_sssq_extended.iloc[0] = df_sssq.iloc[0]\n",
        "\n",
        "# 4. Horizontally concatenate the extended df_sssq DataFrame with df_combined_responses\n",
        "df_questionnaire_responses = pd.concat([df_combined_responses, df_sssq_extended], axis=1)\n",
        "\n",
        "# 5. Print the head and information of the final df_questionnaire_responses DataFrame\n",
        "print(\"--- df_questionnaire_responses head ---\")\n",
        "print(df_questionnaire_responses.head())\n",
        "\n",
        "print(\"\\n--- df_questionnaire_responses info ---\")\n",
        "df_questionnaire_responses.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- df_questionnaire_responses head ---\n",
            "   PANAS_0  PANAS_1  PANAS_2  PANAS_3  PANAS_4  PANAS_5  PANAS_6  PANAS_7  \\\n",
            "0      2.0      1.0      3.0      1.0      1.0      1.0      1.0      1.0   \n",
            "1      2.0      1.0      3.0      4.0      1.0      2.0      1.0      1.0   \n",
            "2      1.0      1.0      2.0      2.0      1.0      1.0      1.0      1.0   \n",
            "3      4.0      4.0      3.0      1.0      3.0      1.0      1.0      4.0   \n",
            "4      2.0      2.0      1.0      1.0      1.0      1.0      1.0      1.0   \n",
            "\n",
            "   PANAS_8  PANAS_9  ...  STAI_4  STAI_5  DIM_0  DIM_1  SSSQ_0  SSSQ_1  \\\n",
            "0      1.0      2.0  ...     1.0     2.0    6.0    2.0     3.0     2.0   \n",
            "1      1.0      3.0  ...     1.0     4.0    8.0    2.0     NaN     NaN   \n",
            "2      1.0      2.0  ...     1.0     1.0    6.0    1.0     NaN     NaN   \n",
            "3      2.0      4.0  ...     2.0     1.0    3.0    8.0     NaN     NaN   \n",
            "4      1.0      2.0  ...     1.0     1.0    6.0    2.0     NaN     NaN   \n",
            "\n",
            "   SSSQ_2  SSSQ_3  SSSQ_4  SSSQ_5  \n",
            "0     2.0     3.0     3.0     2.0  \n",
            "1     NaN     NaN     NaN     NaN  \n",
            "2     NaN     NaN     NaN     NaN  \n",
            "3     NaN     NaN     NaN     NaN  \n",
            "4     NaN     NaN     NaN     NaN  \n",
            "\n",
            "[5 rows x 40 columns]\n",
            "\n",
            "--- df_questionnaire_responses info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 40 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   PANAS_0   5 non-null      float64\n",
            " 1   PANAS_1   5 non-null      float64\n",
            " 2   PANAS_2   5 non-null      float64\n",
            " 3   PANAS_3   5 non-null      float64\n",
            " 4   PANAS_4   5 non-null      float64\n",
            " 5   PANAS_5   5 non-null      float64\n",
            " 6   PANAS_6   5 non-null      float64\n",
            " 7   PANAS_7   5 non-null      float64\n",
            " 8   PANAS_8   5 non-null      float64\n",
            " 9   PANAS_9   5 non-null      float64\n",
            " 10  PANAS_10  5 non-null      float64\n",
            " 11  PANAS_11  5 non-null      float64\n",
            " 12  PANAS_12  5 non-null      float64\n",
            " 13  PANAS_13  5 non-null      float64\n",
            " 14  PANAS_14  5 non-null      float64\n",
            " 15  PANAS_15  5 non-null      float64\n",
            " 16  PANAS_16  5 non-null      float64\n",
            " 17  PANAS_17  5 non-null      float64\n",
            " 18  PANAS_18  5 non-null      float64\n",
            " 19  PANAS_19  5 non-null      float64\n",
            " 20  PANAS_20  5 non-null      float64\n",
            " 21  PANAS_21  5 non-null      float64\n",
            " 22  PANAS_22  5 non-null      float64\n",
            " 23  PANAS_23  5 non-null      float64\n",
            " 24  PANAS_24  1 non-null      float64\n",
            " 25  PANAS_25  1 non-null      float64\n",
            " 26  STAI_0    5 non-null      float64\n",
            " 27  STAI_1    5 non-null      float64\n",
            " 28  STAI_2    5 non-null      float64\n",
            " 29  STAI_3    5 non-null      float64\n",
            " 30  STAI_4    5 non-null      float64\n",
            " 31  STAI_5    5 non-null      float64\n",
            " 32  DIM_0     5 non-null      float64\n",
            " 33  DIM_1     5 non-null      float64\n",
            " 34  SSSQ_0    1 non-null      float64\n",
            " 35  SSSQ_1    1 non-null      float64\n",
            " 36  SSSQ_2    1 non-null      float64\n",
            " 37  SSSQ_3    1 non-null      float64\n",
            " 38  SSSQ_4    1 non-null      float64\n",
            " 39  SSSQ_5    1 non-null      float64\n",
            "dtypes: float64(40)\n",
            "memory usage: 1.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31e587a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b500e3a6-97ff-4473-b160-17c11cf10aae"
      },
      "source": [
        "print(f\"Listing files in {cleaned_data_dir}:\")\n",
        "!ls -F {cleaned_data_dir}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in /content/WESAD_data/WESAD/S10/cleaned_data:\n",
            "chest_s10_acc.csv   chest_s11_eda.csv\t\t    wrist_s10_eda.csv\n",
            "chest_s10_ecg.csv   chest_s11_emg.csv\t\t    wrist_s10_temp.csv\n",
            "chest_s10_eda.csv   chest_s11_resp.csv\t\t    wrist_s11_acc.csv\n",
            "chest_s10_emg.csv   chest_s11_temp.csv\t\t    wrist_s11_bvp.csv\n",
            "chest_s10_resp.csv  df_event_timings.csv\t    wrist_s11_eda.csv\n",
            "chest_s10_temp.csv  df_questionnaire_responses.csv  wrist_s11_temp.csv\n",
            "chest_s11_acc.csv   wrist_s10_acc.csv\n",
            "chest_s11_ecg.csv   wrist_s10_bvp.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8713d937"
      },
      "source": [
        "import os\n",
        "\n",
        "# Ensure the directory exists before navigating\n",
        "os.makedirs(cleaned_data_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Navigating to: {cleaned_data_dir}\")\n",
        "%cd {cleaned_data_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eef9998b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db859751-274f-4f54-a2f8-e42d3f5af8fe"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the directory to save cleaned data\n",
        "cleaned_data_dir = f'{s2_data_path}/cleaned_data'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(cleaned_data_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Saving cleaned data to: {cleaned_data_dir}\")\n",
        "\n",
        "# Save df_event_timings\n",
        "df_event_timings.to_csv(f'{cleaned_data_dir}/df_event_timings.csv', index=False)\n",
        "print(\"Saved df_event_timings.csv\")\n",
        "\n",
        "# Save df_questionnaire_responses\n",
        "df_questionnaire_responses.to_csv(f'{cleaned_data_dir}/df_questionnaire_responses.csv', index=False)\n",
        "print(\"Saved df_questionnaire_responses.csv\")\n",
        "\n",
        "# Save individual chest sensor DataFrames\n",
        "for sensor_name, df in chest_dataframes.items():\n",
        "    df.to_csv(f'{cleaned_data_dir}/chest_{sensor_name.lower()}.csv', index=False)\n",
        "    print(f\"Saved chest_{sensor_name.lower()}.csv\")\n",
        "\n",
        "# Save individual wrist sensor DataFrames\n",
        "for sensor_name, df in wrist_dataframes.items():\n",
        "    df.to_csv(f'{cleaned_data_dir}/wrist_{sensor_name.lower()}.csv', index=False)\n",
        "    print(f\"Saved wrist_{sensor_name.lower()}.csv\")\n",
        "\n",
        "print(\"All cleaned DataFrames saved successfully!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cleaned data to: /content/WESAD_data/WESAD/S10/cleaned_data\n",
            "Saved df_event_timings.csv\n",
            "Saved df_questionnaire_responses.csv\n",
            "Saved chest_s10_acc.csv\n",
            "Saved chest_s10_ecg.csv\n",
            "Saved chest_s10_emg.csv\n",
            "Saved chest_s10_eda.csv\n",
            "Saved chest_s10_temp.csv\n",
            "Saved chest_s10_resp.csv\n",
            "Saved chest_s11_acc.csv\n",
            "Saved chest_s11_ecg.csv\n",
            "Saved chest_s11_emg.csv\n",
            "Saved chest_s11_eda.csv\n",
            "Saved chest_s11_temp.csv\n",
            "Saved chest_s11_resp.csv\n",
            "Saved wrist_s10_acc.csv\n",
            "Saved wrist_s10_bvp.csv\n",
            "Saved wrist_s10_eda.csv\n",
            "Saved wrist_s10_temp.csv\n",
            "Saved wrist_s11_acc.csv\n",
            "Saved wrist_s11_bvp.csv\n",
            "Saved wrist_s11_eda.csv\n",
            "Saved wrist_s11_temp.csv\n",
            "All cleaned DataFrames saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Z0MJaHS7z7XD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390f820b-a045-4a83-d09c-48a751cc4d50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Search for your notebook in Drive\n",
        "# Replace 'data_cleaning' with a keyword from your actual file name if different\n",
        "!find /content/drive/MyDrive -name \"*data_cleaning*.ipynb\"\n",
        "\n",
        "# 2. Once you see the path in the output, copy it here:\n",
        "# Example: !cp \"/content/drive/MyDrive/Colab Notebooks/data_cleaning.ipynb\" /content/\n",
        "# (Make sure to use quotes if there are spaces in the name)"
      ],
      "metadata": {
        "id": "5_NEm9vl1-PF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b8cb38-56cf-42e3-9ab7-8c0684c97792"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Copy of Copy_of_data_cleaning.ipynb\n",
            "/content/drive/MyDrive/Colab Notebooks/Copy_of_data_cleaning.ipynb\n",
            "/content/drive/MyDrive/Academic   Colab Projects/ai_data_cleaning.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    import numpy as np\n",
        "    import scipy.signal\n",
        "    import pandas as pd\n",
        "\n",
        "    def resample_sensor_data(df, target_freq, current_freq):\n",
        "        if 'timestamp' not in df.columns:\n",
        "            print(\"Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\")\n",
        "            num_samples = len(df)\n",
        "            time_duration = num_samples / current_freq\n",
        "            new_num_samples = int(time_duration * target_freq)\n",
        "\n",
        "            resampled_df = pd.DataFrame()\n",
        "            for col in df.columns:\n",
        "                if np.issubdtype(df[col].dtype, np.number): # Only resample numeric columns\n",
        "                    resampled_data = scipy.signal.resample(df[col].values, new_num_samples)\n",
        "                    resampled_df[col] = resampled_data\n",
        "                else:\n",
        "                    # For non-numeric, we can't directly resample, maybe forward fill or skip\n",
        "                    # For now, let's just carry over if index matches, though index won't align\n",
        "                    pass\n",
        "            # Need to create a new time index for resampled_df\n",
        "            new_time_index = np.linspace(0, time_duration, new_num_samples, endpoint=False)\n",
        "            # If we had an original start time, we'd add it here.\n",
        "            # resampled_df['timestamp'] = new_time_index + (original_start_time if available)\n",
        "            # Since we don't have original timestamp, we create a relative one.\n",
        "            resampled_df.insert(0, 'relative_time', new_time_index)\n",
        "\n",
        "        else:\n",
        "            time_seconds = (df['timestamp'] - df['timestamp'].iloc[0]) / np.timedelta64(1, 's')\n",
        "            time_duration = time_seconds.iloc[-1]\n",
        "            new_num_samples = int(time_duration * target_freq)\n",
        "            new_time_index = np.linspace(0, time_duration, new_num_samples, endpoint=False)\n",
        "\n",
        "            resampled_df = pd.DataFrame()\n",
        "            resampled_df['timestamp_new'] = pd.to_timedelta(new_time_index, unit='s') + df['timestamp'].iloc[0]\n",
        "\n",
        "            for col in df.columns:\n",
        "                if col != 'timestamp' and np.issubdtype(df[col].dtype, np.number):\n",
        "                    resampled_data = np.interp(new_time_index, time_seconds.values, df[col].values)\n",
        "                    resampled_df[col] = resampled_data\n",
        "            resampled_df = resampled_df.rename(columns={'timestamp_new': 'timestamp'})\n",
        "\n",
        "        return resampled_df\n",
        "\n",
        "    # Assuming chest_dataframes and wrist_dataframes are already loaded\n",
        "    # and contain DataFrames for each sensor, with original frequencies known.\n",
        "\n",
        "    # Example frequencies (replace with actual frequencies if known and different)\n",
        "    chest_freq = 700\n",
        "    wrist_freqs = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4} # Example freqs for wrist sensors\n",
        "\n",
        "    target_freq = 64\n",
        "\n",
        "    print(\"Resampling chest dataframes...\")\n",
        "    for sensor_name, df in chest_dataframes.items():\n",
        "        print(f\"Resampling {sensor_name} from {chest_freq}Hz to {target_freq}Hz\")\n",
        "        chest_dataframes[sensor_name] = resample_sensor_data(df.copy(), target_freq, chest_freq)\n",
        "        print(f\"New shape of {sensor_name}: {chest_dataframes[sensor_name].shape}\")\n",
        "\n",
        "    print(\"\\nResampling wrist dataframes...\")\n",
        "    for sensor_name, df in wrist_dataframes.items():\n",
        "        current_f = wrist_freqs.get(sensor_name, 32) # Default to 32 if not in map\n",
        "        print(f\"Resampling {sensor_name} from {current_f}Hz to {target_freq}Hz\")\n",
        "        wrist_dataframes[sensor_name] = resample_sensor_data(df.copy(), target_freq, current_f)\n",
        "        print(f\"New shape of {sensor_name}: {wrist_dataframes[sensor_name].shape}\")\n",
        "\n",
        "    print(\"\\nResampling complete.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMecDoMiFdXG",
        "outputId": "3078a38e-9b6e-40ae-864f-d5fb933a0fa5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampling chest dataframes...\n",
            "Resampling S10_ACC from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_ACC: (311663, 4)\n",
            "Resampling S10_ECG from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_ECG: (3281, 2)\n",
            "Resampling S10_EMG from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_EMG: (327, 2)\n",
            "Resampling S10_EDA from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_EDA: (363, 2)\n",
            "Resampling S10_Temp from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_Temp: (124, 2)\n",
            "Resampling S10_Resp from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_Resp: (2309, 2)\n",
            "Resampling S11_ACC from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_ACC: (314217, 4)\n",
            "Resampling S11_ECG from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_ECG: (3974, 2)\n",
            "Resampling S11_EMG from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_EMG: (494, 2)\n",
            "Resampling S11_EDA from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_EDA: (534, 2)\n",
            "Resampling S11_Temp from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_Temp: (106, 2)\n",
            "Resampling S11_Resp from 700Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_Resp: (3128, 2)\n",
            "\n",
            "Resampling wrist dataframes...\n",
            "Resampling S10_ACC from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_ACC: (45378, 4)\n",
            "Resampling S10_BVP from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_BVP: (62438, 2)\n",
            "Resampling S10_EDA from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_EDA: (5408, 2)\n",
            "Resampling S10_TEMP from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S10_TEMP: (392, 2)\n",
            "Resampling S11_ACC from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_ACC: (73958, 4)\n",
            "Resampling S11_BVP from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_BVP: (56788, 2)\n",
            "Resampling S11_EDA from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_EDA: (6732, 2)\n",
            "Resampling S11_TEMP from 32Hz to 64Hz\n",
            "Timestamp column missing, cannot resample based on time. Assuming uniform sampling.\n",
            "New shape of S11_TEMP: (306, 2)\n",
            "\n",
            "Resampling complete.\n"
          ]
        }
      ]
    }
  ]
}